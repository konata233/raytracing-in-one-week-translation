<!DOCTYPE html>
<meta charset="utf-8">
<link rel="icon" type="image/png" href="../favicon.png">
<!-- Markdeep: https://casual-effects.com/markdeep/ -->


                                    **一个周末手搓光追**
                    Peter Shirley, Trevor David Black, Steve Hollasch
                                        <br>
                                Version 4.0.1, 2024-08-31
                                        <br>
                Copyright 2018-2024 Peter Shirley. All rights reserved.



译者注：

原作者的注释以**加粗**表示，译者的注释以_斜体_表示。没有字体变化，且未标注注释者处，默认视作原作者的注释。

原文中以斜体表示强调的部分，译文中用加粗表示。另外，文中有一些虽然是重点但作者并未专门强调的部分。
此时，译者也会酌情以加粗形式标出。

译者尽可能保证对原文的尊重，但也进行了少量的转述、压缩、展开说明或顺序调换。



综述
====================================================================================================
这么多年间，我教过相当多的图形学课程。大部分时候，我都教学生光线追踪（ray tracing），因为虽然他们要被迫编写全部的代码，
但却仍然能在完全不使用 API 的情况下得到一些不错的图像。最后，我决定把我所有的课程笔记整理成一个教程，
以求让你在尽可能短的时间内做出一个炫酷的光追程序。当然了，它的功能并不完善。
但这不妨碍它具有间接光照（indirect lighting）的功能——这使得光追这一技术在电影行业成为了主流。
按照这个教程一步步做完后，如果你学有余力，并且还有更高追求的话，完全可以利用这一光追程序的基础架构，扩充出一个更强大的版本。

当有人提到“光追”的时候，他指的可能是许多东西之一。而我在这里指的“光追”实际上是基于很常规的路径追踪（path tracing）
来实现的。由于相关的代码都十分简单（大部分的工作都由电脑帮你做了），看到它生成的图像时，你应该会又惊又喜。

我会按照我编写一个光追程序的顺序来指导你，同时给出一些调试的建议。只消大约一个周末的时间，
你就可以得到一个可以生成厉害图像的光追渲染器。话虽如此，你花了更多时间也不必担心。我使用 C++ 语言进行开发，你也可以选用别的语言。
但我仍然建议你使用 C++，因为它足够快、可移植性强，并且大部分的电影或游戏渲染器都是用 C++ 编写的。注意，
我避免使用相当一部分 C++ 的所谓“现代”特性，但是继承和运算符重载确实太好用了，所以在我们的渲染器里用一用无可厚非。

> 我没有在网上发布这些代码，但是它们都是货真价实的，除了极个别毫无实现难度的 `vec3` 类的运算符重载的代码未展示外，
> 其余的代码都已经写在书里了。我坚持认为学习编程的最好办法就是自己上手去写，所以不要再问我有没有现成的代码了！
> 当然啦，如果有现成的代码，我还是会去用的；我只会在没有现成的代码的情况下，才会身体力行我刚提到的观念。

我最后还是把前面那一段留下了，因为我自己的态度发生 180 度大转弯这件事实在好笑。我的态度之所以改变，是因为有几位读者的代码出了各式各样的小差错，
而这些差错均在我们对比代码后解决了。综上，我还是恳请诸位读者先自己写一遍代码，
不过有需要的话，你随时可以在 [这里](https://github.com/RayTracing/raytracing.github.io) 找到全书的完整示例代码。

几项原则：

 - 代码必须实现书中涉及到的所有概念；

 - 尽管使用的是 C++，但我们尽可能把它写的简单一点。（事实上，本书示例代码的编程风格相当接近 C 语言）
   不过，也会使用部分 C++ 的现代特性，以期获得更简明扼要的代码。

所有的代码只是给出了一个基本的实现，遗留了大量改进空间。这就有待读者诸君自己去享受编程的快乐了。
优化和重构这些代码的方法千千万，但在一开始我们还是选择简单一点的解决方案。

我假定本书的读者对向量的知识（例如向量的点乘、相加等）有着一定的熟悉度。如果你对这些概念没什么印象，
那我建议你还是稍微复习一下。对于那些需要从头开始学习相关知识，或者确需复习的读者，
考虑参阅以下几本书：

 - Morgan McGuire 的 _Graphics Codex_

 - Steve Marschner and Peter Shirley 的 _Fundamentals of Computer Graphics_

 - J.D. Foley 和 Andy Van Dam 的 _Computer Graphics: Principles and Practice_

>
> 更多信息，敬请参阅 Github 上的原项目仓库，及本书原文的有关段落。——译者
>

那么，让我们开始吧！



输出一个图像
====================================================================================================

PPM 格式
---------------------
如果你想要做一个渲染器，你首先得找一个方法看到渲染出的图像。最直接的办法就是将渲染结果写入一个文件。问题在于，
图像文件的格式实在是多如牛毛，其中大多一个比一个复杂。我一般习惯从纯文本的 PPM 格式入手。以下是维基百科上面的介绍：

    ![Figure [ppm]: PPM Example](../images/fig-1.01-ppm.jpg)

<div class='together'>
来写点代码输出一个 PPM 图像文件吧。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include <iostream>

    int main() {

        // Image

        int image_width = 256;
        int image_height = 256;

        // Render

        std::cout << "P3\n" << image_width << ' ' << image_height << "\n255\n";

        for (int j = 0; j < image_height; j++) {
            for (int i = 0; i < image_width; i++) {
                auto r = double(i) / (image_width-1);
                auto g = double(j) / (image_height-1);
                auto b = 0.0;

                int ir = int(255.999 * r);
                int ig = int(255.999 * g);
                int ib = int(255.999 * b);

                std::cout << ir << ' ' << ig << ' ' << ib << '\n';
            }
        }
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [main-initial]: <kbd>[main.cc]</kbd> 渲染第一张图像的代码]

</div>

这里有几个值得注意的点：

 1. 所有的像素按行被写入；

 2. 每一行的像素从左向右依次被写入；

 3. 所有的行从上往下依次被写入；

 4. 一般说来，每一个像素的 R/G/B 通道在渲染器内部都被表示为 0.0 ~ 1.0 之间的实数变量。在被写入到文件之前，
    它们必须被放大至 0 ~ 255 之间的整型值。

 5. 从左至右，R 通道（红色）从全关（黑色）到全开（亮红）；从上至下，G 通道（绿色）也是类似的变化规律。我们知道，
    将红绿两种颜色混合，可以得到黄色，因此我们大可以推测图像的右下角是黄色的。


将渲染结果写入一个图像文件
-----------------------
图像文件的数据被写入标准输出流，因此你需要将输出重定向至一个图像文件。一般说来，在终端上，这通过 `>` 重定向
操作符实现。

在 Windows 操作系统上，你可以使用 cmake 生成程序的 debug 构建：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cmake -B build
cmake --build build
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

接着像这样运行你刚刚构建好的程序：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
build\Debug\inOneWeekend.exe > image.ppm
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

以后，为了执行速度方面的考量，最好按照以下方式生成优化过的构建：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cmake --build build --config release
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

然后这样执行优化后的程序：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
build\Release\inOneWeekend.exe > image.ppm
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

以上的案例均默认你使用 cmake 进行程序构建，一如本书所附的源代码中 `CMakeLists.txt` 文件所使用的方法。
当然，你也可以按照你的喜好，使用最适合你的构建环境（或者语言）。

在 Mac 或者 Linux 下，使用 release 构建的情况下，你应当像这样执行你的程序：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
build/inOneWeekend > image.ppm
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

完整的构建和执行指南可以在本项目的 Readme 中找到。_（详请参阅 Github 上原项目。——译者）_

打开输出的文件（在我的 Mac 电脑上用 `ToyViewer` 打开，但是你亦可以尝试用你喜欢的图像浏览器打开它；如果
无法打开，考虑搜索“PPM Viewer”），显示以下内容：

![<span class='num'>Image 1:</span> 第一个 PPM 图像
](../images/img-1.01-first-ppm-image.png class='pixel')

如果你看到了这样的一张图片，那么恭喜你，你已经做出了图形学的 hello world 了。_（图形学的 hello world 
不是三角形嘛……顺带一提，更早的一位译者也吐槽了这里。如果你现在就要做各种平面三角形之类的，敬请阅读本书的
续作《两个周末手搓光追》即 Ray Tracing: The Next Week，或者观看闫令琪老师的 GAMES 101 系列图形学课程视频。——译者）_
如果你的图片不是这样的，用一个文本编辑器打开这个文件，看看里面是什么状况。它的开头应当长这样：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
P3
256 256
255
0 0 0
1 0 0
2 0 0
3 0 0
4 0 0
5 0 0
6 0 0
7 0 0
8 0 0
9 0 0
10 0 0
11 0 0
12 0 0
...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
[Listing [first-img]: 第一个图像输出]

如果你的 PPM 图像的文本与此处展示的不符，请重新检查你用以格式化输出颜色的代码。如果它**确实**看起来像这样，但是
仍然显示不出来，那么可能是有一些行尾（line-ending）的不一致，或者其他类似的原因，致使你的图片查看器无法正确
解析 PPM 图像。要找到究竟哪里出了问题，你可以在 Github 上原项目的 `images` 目录下找到一个 `test.ppm` 文件。
第一，它可以帮助你确认你的图像查看器支持 PPM 格式；第二，它可以作为你自己生成的 PPM 文件的对照。

有一部分读者也报告称，在 Windows 系统上浏览他们生成的图片时出现了问题。这一般是因为在 Powershell 环境下
写入 PPM 文件时采用了 UTF-16 编码。如果你遇到了这种情况，请参阅 Github 上的
[Discussion 1114](https://github.com/RayTracing/raytracing.github.io/discussions/1114)，
这对解决你的问题或许能起到一定帮助。

如果你的图片能够正常显示，说明你已经解决了绝大多数系统或 IDE 造成的问题。剩下的就只是用类似的方法输出其他的渲染图了。

当然，如果你希望输出别的图像格式，我个人力荐 `stb_image.h`，一个单头文件的图像库。
参见它的 Github 仓库： <https://github.com/nothings/stb>。


添加一个渲染进度指示
----------------------------
在继续之前，先为我们的程序添加一个渲染进度指示吧。这可以帮助你跟踪一个较长的渲染的进度，
也对你发现运行中死循环等问题导致的阻塞大有裨益。

<div class='together'>
由于我们的程序将图像文件输出至标准输出流（`std::cout`），所以我们改用日志输出流（`std::clog`）来输出渲染进度。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
        for (int j = 0; j < image_height; ++j) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            std::clog << "\rScanlines remaining: " << (image_height - j) << ' ' << std::flush;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            for (int i = 0; i < image_width; i++) {
                auto r = double(i) / (image_width-1);
                auto g = double(j) / (image_height-1);
                auto b = 0.0;

                int ir = int(255.999 * r);
                int ig = int(255.999 * g);
                int ib = int(255.999 * b);

                std::cout << ir << ' ' << ig << ' ' << ib << '\n';
            }
        }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        std::clog << "\rDone.                 \n";
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [main-progress]: <kbd>[main.cc]</kbd> 添加了渲染进度指示的主渲染循环]

</div>

现在，运行你的程序的时候，你便可以看到一个不断变化的数字，指示着还有多少行有待扫描。它现在变化得应该相当快，导致我们难以看清。
不过，放心好了。随着我们的光追程序逐渐扩充，看一个慢条斯理的进度的机会有的是。



vec3 向量类
====================================================================================================
几乎所有图形学相关的程序都有一些用于存储向量和颜色的类。许多程序中，这些向量/颜色都是四维的（除基本的三维向量外，
在几何学计算下，外加了一维齐次坐标；在颜色计算下，外加了一个 alpha 透明度通道）。但是，对于我们想要达到的目的
而言，三维坐标已经绰绰有余了。

同时，我们也将把 `vec3` 向量类用于颜色、位置、方位、偏移量等等的表示。有一部分人比较抵触这种做法。
他们认为这样做没法阻止你干一些很蠢的事情，比如用颜色减去位置等等。他们的质疑不无道理，但是我们已经铁了心
要在“代码越少越好”这条路上走到黑了（前提是没有明显的错误）。即便如此，为避免可能的混淆，我们还是要创建
`vec3` 类的两个别名，分别为 `point3` 和 `color`。不过注意，由于它们只是 `vec3` 的**别名**，就算你给
一个要求形参为 `point3` 的函数传递一个 `color` 的实参，编译器也不会给出警告。同样的，你也完全可能在不知不觉间
将一个 `point3` 和一个 `color` 相加。我们这么做，只是为了增强代码的可读性。

创建一个 `vec3.h` 头文件。在这个文件的前半部分，我们定义 `vec3` 类的结构；在它的后半部分，我们定义一系列
向量类的工具函数。


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #ifndef VEC3_H
    #define VEC3_H

    #include <cmath>
    #include <iostream>

    class vec3 {
    public:
        double e[3];

        vec3() : e{0,0,0} {}
        vec3(double e0, double e1, double e2) : e{e0, e1, e2} {}

        double x() const { return e[0]; }
        double y() const { return e[1]; }
        double z() const { return e[2]; }

        vec3 operator-() const { return vec3(-e[0], -e[1], -e[2]); }
        double operator[](int i) const { return e[i]; }
        double& operator[](int i) { return e[i]; }

        vec3& operator+=(const vec3& v) {
            e[0] += v.e[0];
            e[1] += v.e[1];
            e[2] += v.e[2];
            return *this;
        }

        vec3& operator*=(double t) {
            e[0] *= t;
            e[1] *= t;
            e[2] *= t;
            return *this;
        }

        vec3& operator/=(double t) {
            return *this *= 1/t;
        }

        double length() const {
            return std::sqrt(length_squared());
        }

        double length_squared() const {
            return e[0]*e[0] + e[1]*e[1] + e[2]*e[2];
        }
    };

    // point3 is just an alias for vec3, but useful for geometric clarity in the code.
    using point3 = vec3;


    // Vector Utility Functions

    inline std::ostream& operator<<(std::ostream& out, const vec3& v) {
        return out << v.e[0] << ' ' << v.e[1] << ' ' << v.e[2];
    }

    inline vec3 operator+(const vec3& u, const vec3& v) {
        return vec3(u.e[0] + v.e[0], u.e[1] + v.e[1], u.e[2] + v.e[2]);
    }

    inline vec3 operator-(const vec3& u, const vec3& v) {
        return vec3(u.e[0] - v.e[0], u.e[1] - v.e[1], u.e[2] - v.e[2]);
    }

    inline vec3 operator*(const vec3& u, const vec3& v) {
        return vec3(u.e[0] * v.e[0], u.e[1] * v.e[1], u.e[2] * v.e[2]);
    }

    inline vec3 operator*(double t, const vec3& v) {
        return vec3(t*v.e[0], t*v.e[1], t*v.e[2]);
    }

    inline vec3 operator*(const vec3& v, double t) {
        return t * v;
    }

    inline vec3 operator/(const vec3& v, double t) {
        return (1/t) * v;
    }

    inline double dot(const vec3& u, const vec3& v) {
        return u.e[0] * v.e[0]
            + u.e[1] * v.e[1]
            + u.e[2] * v.e[2];
    }

    inline vec3 cross(const vec3& u, const vec3& v) {
        return vec3(u.e[1] * v.e[2] - u.e[2] * v.e[1],
                    u.e[2] * v.e[0] - u.e[0] * v.e[2],
                    u.e[0] * v.e[1] - u.e[1] * v.e[0]);
    }

    inline vec3 unit_vector(const vec3& v) {
        return v / v.length();
    }

    #endif
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [vec3-class]: <kbd>[vec3.h]</kbd> vec3 定义与工具函数]

在这里与一部分光追程序不同的是，我们使用双精度浮点数（double）替代了单精度浮点数（float）。双精度浮点数精度更高、
范围更广，但其占用的内存空间也是单精度浮点数的两倍。如果你只有有限的内存资源（比如硬件），此时内存占用这一问题就不可忽视了。
按照你自己的偏好和实际需求选用其一即可。


颜色的工具函数
------------------------
藉由我们刚刚编写的 `vec3` 类，我们创建一个新的头文件 `color.h` 并定义一个将单个像素的颜色写入标准输出流的工具函数。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #ifndef COLOR_H
    #define COLOR_H

    #include "vec3.h"

    #include <iostream>

    using color = vec3;

    void write_color(std::ostream& out, const color& pixel_color) {
        auto r = pixel_color.x();
        auto g = pixel_color.y();
        auto b = pixel_color.z();

        // Translate the [0,1] component values to the byte range [0,255].
        int rbyte = int(255.999 * r);
        int gbyte = int(255.999 * g);
        int bbyte = int(255.999 * b);

        // Write out the pixel color components.
        out << rbyte << ' ' << gbyte << ' ' << bbyte << '\n';
    }

    #endif
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [color]: <kbd>[color.h]</kbd> 颜色工具函数]

<div class="together">

接下来就可以在 main 文件中包含这两个头文件了：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include "color.h"
    #include "vec3.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

    #include <iostream>

    int main() {

        // Image

        int image_width = 256;
        int image_height = 256;

        // Render

        std::cout << "P3\n" << image_width << ' ' << image_height << "\n255\n";

        for (int j = 0; j < image_height; j++) {
            std::clog << "\rScanlines remaining: " << (image_height - j) << ' ' << std::flush;
            for (int i = 0; i < image_width; i++) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                auto pixel_color = color(double(i)/(image_width-1), double(j)/(image_height-1), 0);
                write_color(std::cout, pixel_color);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            }
        }

        std::clog << "\rDone.                 \n";
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [ppm-2]: <kbd>[main.cc]</kbd> 生成第一个 PPM 图像的最终代码]

</div>

你应该可以得到一张和上次生成结果完全一致的图像。



光线、相机和背景
====================================================================================================

ray 光线类
--------------

> 为了防止引起困惑，我在这里先提一嘴，采用译法“光线”虽然可以省事，却并不能很好地体现我们使用的方案的实质：**光路可逆性**。目前而言，环境中并没有什么“光线”进入了摄像机；
> 相反，是摄像机自身向场景中“发射了”一束束假想的射线——不妨称其为“观察射线”——这些“观察射线”在场景中发生反射折射等等，并对沿途物体的颜色执行混合等操作。
> ——译者

所有的光追程序都有这样的共性：一个光线类，以及用来得到在某条光线的方向上，可以看到何种颜色的计算。我们可以把光线看作这样的
一个函数： $\mathbf{P}(t) = \mathbf{A} + t \mathbf{b}$ 。其中，$\mathbf{P}$ 是在三维空间内的一条直线上的某一点，
$\mathbf{A}$ 是光线的原点（origin）， $\mathbf{b}$ 是光线的方向。这个光线函数的自变量 $t$ 是一个实数（在我们的
程序中，它被存储为 `double` 类型）。输入不同的 $t$，点 $\mathbf{P}$ 便会沿着光线的方向移动。输入一个取值为任意实数的
$t$，你就可以取到光线所在直线上的任意一点。但是对于正数 $t$，你只能取到 $\mathbf{A}$ “前面”的“半条直线”，也就是射线或者光线。

    ![Figure [lerp]: Linear interpolation](../images/fig-1.02-lerp.jpg)

<div class="together">

考虑使用一个类来表示光线。同时，用一个名叫 `ray::at(t)` 的方法来表示函数 $\mathbf{P}(t)$ ：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #ifndef RAY_H
    #define RAY_H

    #include "vec3.h"

    class ray {
      public:
        ray() {}

        ray(const point3& origin, const vec3& direction) : orig(origin), dir(direction) {}

        const point3& origin() const  { return orig; }
        const vec3& direction() const { return dir; }

        point3 at(double t) const {
            return orig + t*dir;
        }

      private:
        point3 orig;
        vec3 dir;
    };

    #endif
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [ray-initial]: <kbd>[ray.h]</kbd> ray 光线类]

</div>

（如果你对 C++ 不甚了解，可以看看这些额外说明：函数 `ray::origin()` 和 `ray::direction()` 均返回对于 `ray` 类的
成员，即 `ray::orig` 和 `ray::dir` 的不可变引用。取决于实际需求，调用方可以直接使用这个引用，也可以创建一个
这个成员的可变的拷贝。）


向场景中发射光线
----------------------------
我们总算可以着手做光追渲染器了！一个光追渲染器的核心通过发射一系列穿过 _（视口的，参见下文）_ 每个像素中心的光线，
并计算这些光线方向上所能“看见”的颜色。这一操作包含以下几个步骤：

    1. 计算从“眼睛”_（观察点）_ 到每个视口像素的方向；
    2. 判断光线和哪些物体相交了；
    3. 计算_（距离观察点）_最近的一个相交点的颜色。

在开始做一个光追渲染器的时候，我一般会先实现一个简单的相机，好让我的代码可以尽快运行起来看到结果。

使用正方形的图片进行调试的时候，我总是遇到各种问题，因为我时常转置 $x$ 和 $y$。因此，我们选择生成一个不是正方形的图片。我们知道，
正方形的图片宽高相等，因此显然它的宽高比（aspect ratio）为 1&ratio;1。我们的图像使用一个比较普遍的宽高比，即 16&ratio;9。

    $$\text{width} / \text{height} = 16 / 9 = 1.7778$$

图像的宽高比、宽、高三者知二求一。既然我们使用一个确定的宽高比，不妨用宽度和宽高比来反过来确定图像的高度。
这样，需要放大或缩小图片时，只需要保持宽高比不变，更改图像的宽度即可。只是，要保证通过宽度和宽高比
计算得到的高度大于 1。

除了设置目标图像的宽高像素数，我们还需要设置一个虚拟的 **视口** (viewport)。我们的光线都会穿过这个视口。
所谓视口是一个三维空间中的假想的矩形，它包含了图像中像素构成的网格。假如像素之间的水平距离与垂直距离相等，那么
容纳它们的视口的宽高比将会和目标图像的宽高比完全一致。正方形的像素作为基准的话，临近的两个像素之间的距离称作
像素间距（pixel spacing）。

我们先确定一个**视口高度**，不妨选择 2.0，通过缩放**视口宽度**，得到我们想要的宽高比。代码如下：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    auto aspect_ratio = 16.0 / 9.0;
    int image_width = 400;

    // Calculate the image height, and ensure that it's at least 1.
    int image_height = int(image_width / aspect_ratio);
    image_height = (image_height < 1) ? 1 : image_height;

    // Viewport widths less than one are ok since they are real valued.
    auto viewport_height = 2.0;
    auto viewport_width = viewport_height * (double(image_width)/image_height);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [image-setup]: 图像渲染初始化]

你可能对为什么我们不直接使用 `aspect_ratio`（即宽高比）和视口高度计算得到 `viewport_width`（即视口宽度）感到疑惑。
请注意，我们设定的 `aspect_ratio` 是一个**理想情况**下的比例，它不一定就是**实际的** `image_width` 和 `image_height`
（即图片宽、高）的比例。假如 `image_height` 可以取任意值（而非整型值）的话，直接用 `aspect_ratio` 完全合适。
然而问题就在于，`image_width` 和 `image_height` 的**实际的**比例，与它们的**理想的**比例之间可能存在不一致。
这是由于：第一，`image_height` 被向下取整为了一个整数，这会增加实际的比例；第二，我们不允许 `image_height` 比一小，
这也可能改变实际的比例。

所以，请务必注意，`aspect_ratio` 只是一个我们试图用作为整数的 `image_width` 和作为整数的 `image_height` 之比，
去尽可能拟合的一个理想情况下的比例。而为了使视口的宽高比与图像的宽高比完全对应，我们使用**重新计算的图形宽高比**
（而非理想的宽高比）和视口高度来得到视口的宽度。

接下来我们定义相机中心——一个三维空间中的点，而我们所有的光线都会从这一点（常被称作“视点”，eye point）发出。从相机中心
指向视口中心的向量，将会垂直于视口平面。我们现在先将相机中心与视口的距离设为 1 单位长度。从相机中心到视口的这一距离常被
称作**焦距**（focal length）。

为了简单起见，我们先将相机中心设为 $(0,0,0)$ 。我们同时定义 $+y$ 方向指向正上方，$+x$ 方向指向右方，$-z$ 方向指向观察的方向。
这样的坐标系一般被称为**右手坐标系**（right-handed coordinates）。

    ![Figure [camera-geom]: 相机的几何关系](../images/fig-1.03-cam-geom.jpg)

现在有一个不可避免的问题：虽然我们像上文那样规定了三维空间，但这一规定与我们图像坐标之间存在冲突。因为在图像坐标空间中，
我们希望第 0 个像素位于左上角，最后一个像素位于右下角，也就意味着此时 $+y$ 方向是**朝下**的。

在我们扫描图像的时候，我们会从左上角的像素（也就是 $0,0$）开始，从左向右扫描。扫描完这一行，再扫描它下方的一行。
为了方便在像素网格中定位，我们引入两个向量：一个从视口左边缘指向右边缘的向量（$\mathbf{V_u}$），
和一个从视口上边缘指向下边缘的向量（$\mathbf{V_v}$）。

我们在距离视口上边缘、左边缘均为 0.5 个像素间距的位置嵌入像素网格。这样，视口便被均匀分割成了 宽&times;高
个完全相同的区域。下图展示了视口和像素网格的样子：

    ![Figure [pixel-grid]: 视口与像素网格](../images/fig-1.04-pixel-grid.jpg)

在上图中，我们可以看到 7&times;5 分辨率的视口和像素网格各一个，以及视口左上角的点 $\mathbf{Q}$、第零个像素 $\mathbf{P_{0,0}}$、
视口向量 $\mathbf{V_u}$ （`viewport_u`） 和 $\mathbf{V_v}$（`viewport_v`），还有像素间距向量
$\mathbf{\Delta u}$ 和 $\mathbf{\Delta v}$。

<div class="together">

综合以上内容，我们得到了相机的实现代码。添加一个名叫 `ray_color(const ray& r)` 的函数，它返回一束指定的光线的颜色。
我们暂时把这个函数的返回值设为黑色。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include "color.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include "ray.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include "vec3.h"

    #include <iostream>


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    color ray_color(const ray& r) {
        return color(0,0,0);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

    int main() {

        // Image


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        auto aspect_ratio = 16.0 / 9.0;
        int image_width = 400;

        // Calculate the image height, and ensure that it's at least 1.
        int image_height = int(image_width / aspect_ratio);
        image_height = (image_height < 1) ? 1 : image_height;

        // Camera

        auto focal_length = 1.0;
        auto viewport_height = 2.0;
        auto viewport_width = viewport_height * (double(image_width)/image_height);
        auto camera_center = point3(0, 0, 0);

        // Calculate the vectors across the horizontal and down the vertical viewport edges.
        auto viewport_u = vec3(viewport_width, 0, 0);
        auto viewport_v = vec3(0, -viewport_height, 0);

        // Calculate the horizontal and vertical delta vectors from pixel to pixel.
        auto pixel_delta_u = viewport_u / image_width;
        auto pixel_delta_v = viewport_v / image_height;

        // Calculate the location of the upper left pixel.
        auto viewport_upper_left = camera_center
                                 - vec3(0, 0, focal_length) - viewport_u/2 - viewport_v/2;
        auto pixel00_loc = viewport_upper_left + 0.5 * (pixel_delta_u + pixel_delta_v);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        // Render

        std::cout << "P3\n" << image_width << " " << image_height << "\n255\n";

        for (int j = 0; j < image_height; j++) {
            std::clog << "\rScanlines remaining: " << (image_height - j) << ' ' << std::flush;
            for (int i = 0; i < image_width; i++) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                auto pixel_center = pixel00_loc + (i * pixel_delta_u) + (j * pixel_delta_v);
                auto ray_direction = pixel_center - camera_center;
                ray r(camera_center, ray_direction);

                color pixel_color = ray_color(r);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
                write_color(std::cout, pixel_color);
            }
        }

        std::clog << "\rDone.                 \n";
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [creating-rays]: <kbd>[main.cc]</kbd> 创建光线]

</div>

注意，在上面的代码中，我没有把 `ray_direction` 设为一个方向向量。这单纯因为我认为这样做可以使代码更快更简洁。

现在我们要填充 `ray_color(ray)` 函数，来实现一个简单的渐变效果。这个函数会把光线的方向向量缩放为一个单位向量，
再根据得到的单位向量的 $y$ 分量 （此时 $-1.0 < y < 1.0$）混合蓝色和白色。最后我们可以得到一个竖直的、自上而下的蓝-白渐变。

一个常用的图形学技巧叫做线性混合（linear blend），亦作**线性插值**（linear interpolation）。举例来说，对于
$0.0 ≤ a ≤ 1.0$， 我们希望在 $a = 0.0$ 的时候得到白色，在 $a = 1.0$ 的时候得到蓝色。而在这两个值之间，得到两种颜色的混合。
这也被称为这两个值的“lerp”，它的一般形式如下：

$$ \mathit{blendedValue} = (1-a)\cdot\mathit{startValue} + a\cdot\mathit{endValue}, $$

其中，$0.0 ≤ a ≤ 1.0$.

<div class='together'>

合并以上内容，我们得到：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include "color.h"
    #include "ray.h"
    #include "vec3.h"

    #include <iostream>


    color ray_color(const ray& r) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        vec3 unit_direction = unit_vector(r.direction());
        auto a = 0.5*(unit_direction.y() + 1.0);
        return (1.0-a)*color(1.0, 1.0, 1.0) + a*color(0.5, 0.7, 1.0);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    }

    ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [main-blue-white-blend]: <kbd>[main.cc]</kbd> 渲染一个蓝-白渐变]

</div>

<div class='together'>
我们得到：
    
    ![<span class='num'>Image 2:</span> 一个根据光线的 y 分量的蓝-白渐变
    ](../images/img-1.02-blue-to-white.png class='pixel')
    
</div>

_这里其实是实现了一个类似于天空盒或者全局光照（ambient illumination）的功能。_
_因为目前我们并没有实现光源（这一部分内容请参见续作《两个周末手搓渲染器》）。假如没有这个“全局光照”的话，_
_你后面无论做什么漫反射全反射折射，渲染出来的图像都是一片黑。_
_你设成纯色也不会有什么影响，但是看起来丑。——译者_



添加一个球面
====================================================================================================
来为我们的光追渲染器添加一个物体吧。一般我们先添加球面，因为判断一束光线是否与其相交相对简单。


光线与球面的相交
------------------------
我们知道，对于球心位于原点，半径为 $r$ 的球，其方程如下：

    $$ x^2 + y^2 + z^2 = r^2 $$

显然，对于点 $(x,y,z)$，有：

 - 若该点在**球面上**，有 $x^2 + y^2 + z^2 = r^2$；
 - 若该点在**球面内**，有 $x^2 + y^2 + z^2 < r^2$；
 - 若该点在**球面外**，有 $x^2 + y^2 + z^2 > r^2$.

对于球心位于任意一点 $(C_x, C_y, C_z)$，半径为 $r$ 的球，它的方程如下：

    $$ (C_x - x)^2 + (C_y - y)^2 + (C_z - z)^2 = r^2 $$

在图形学中，我们倾向于使用向量的形式表示这些方程。注意到从点 $\mathbf{P} = (x,y,z)$ 指向球心点
$\mathbf{C} = (C_x, C_y, C_z)$ 的向量可以表示为 $(\mathbf{C} - \mathbf{P})$.

又由向量点乘，我们得到：

$$ (\mathbf{C} - \mathbf{P}) \cdot (\mathbf{C} - \mathbf{P})
= (C_x - x)^2 + (C_y - y)^2 + (C_z - z)^2
$$

由上述公式，容易写出球面方程的向量表示：

    $$ (\mathbf{C} - \mathbf{P}) \cdot (\mathbf{C} - \mathbf{P}) = r^2 $$

上文提到，任何一个满足此方程的点 $\mathbf{P}$ 都在球面上。我们现在试图弄清楚的问题是，
光线 $\mathbf{P}(t) = \mathbf{Q} + t\mathbf{d}$ 是否与球面相交；如果相交的话，
当 $t$ 取何值时，得到的点 $\mathbf{P}(t)$ 在球面上。联立球面方程与光线的方程，得到：

    $$ (\mathbf{C} - \mathbf{P}(t)) \cdot (\mathbf{C} - \mathbf{P}(t)) = r^2 $$

展开 $\mathbf{P}(t)$ 得到：

    $$ (\mathbf{C} - (\mathbf{Q} + t \mathbf{d}))
      \cdot (\mathbf{C} - (\mathbf{Q} + t \mathbf{d})) = r^2 $$

在等式的左侧，我们得到了一个 3 个向量点乘 3 个向量的式子。鉴于我们只需要解得 $t$，就没必要将它全部展开了。
我们只需将含有 $t$ 的项单独提出来，如下式：

    $$ (-t \mathbf{d} + (\mathbf{C} - \mathbf{Q})) \cdot (-t \mathbf{d} + (\mathbf{C} - \mathbf{Q}))
    = r^2
    $$

由向量运算法则，将上式部分展开，得：

    $$ t^2 \mathbf{d} \cdot \mathbf{d}
    - 2t \mathbf{d} \cdot (\mathbf{C} - \mathbf{Q})
    + (\mathbf{C} - \mathbf{Q}) \cdot (\mathbf{C} - \mathbf{Q}) = r^2
    $$

将 $r^2$ 移项，得：

$$ t^2 \mathbf{d} \cdot \mathbf{d}
- 2t \mathbf{d} \cdot (\mathbf{C} - \mathbf{Q})
+ (\mathbf{C} - \mathbf{Q}) \cdot (\mathbf{C} - \mathbf{Q}) - r^2 = 0
$$

虽然这个式子看起来可能有些复杂，但是里面的向量和球面半径 $r$ 都是已知的。
而且，所有的向量都已经通过点乘转化为了标量。唯一的未知数就是 $t$ 了。
因此，这个式子实际上就是一个一元二次方程。我们知道求根公式：

    $$ \frac{-b \pm \sqrt{b^2 - 4ac}}{2a} $$

其中的 $a$，$b$，$c$ 在这里分别为：

    $$ a = \mathbf{d} \cdot \mathbf{d} $$
    $$ b = -2 \mathbf{d} \cdot (\mathbf{C} - \mathbf{Q}) $$
    $$ c = (\mathbf{C} - \mathbf{Q}) \cdot (\mathbf{C} - \mathbf{Q}) - r^2 $$

现在我们可以尝试解 $t$ 的值了。但是基于实际的几何关系，我们得到的根的数量可能不同，如下图所示：

    ![Figure [ray-sphere]: 光线与球面的相交的可能结果](../images/fig-1.05-ray-sphere.jpg)


生成第一张光追图像
-----------------------------------
将上文的公式改写为代码实现。同时，我们硬编码一个位于 $(0,0,-1)$ 的小球，并将其涂成红色，以便于我们调试代码。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    bool hit_sphere(const point3& center, double radius, const ray& r) {
        vec3 oc = center - r.origin();
        auto a = dot(r.direction(), r.direction());
        auto b = -2.0 * dot(r.direction(), oc);
        auto c = dot(oc, oc) - radius*radius;
        auto discriminant = b*b - 4*a*c;
        return (discriminant >= 0);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    color ray_color(const ray& r) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        if (hit_sphere(point3(0,0,-1), 0.5, r))
            return color(1, 0, 0);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        vec3 unit_direction = unit_vector(r.direction());
        auto a = 0.5*(unit_direction.y() + 1.0);
        return (1.0-a)*color(1.0, 1.0, 1.0) + a*color(0.5, 0.7, 1.0);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [main-red-sphere]: <kbd>[main.cc]</kbd> 渲染一个红色小球]


<div class="together">
我们得到：

  ![<span class='num'>Image 3:</span> 渲染得到的红色小球图片
  ](../images/img-1.03-red-sphere.png class='pixel')

</div>

虽然这个孤零零的球看起来相当寒酸——着色、反射什么都没有，但是其实我们已经做了相当多工作了！
只是有一点要注意，那就是在计算光线与球面相交时，我们只考虑了得到的 $t$ 的根是否为实数，却没有考虑其**正负性**。
不信你可以把球移到 $(0,0,+1)$，看看渲染出来的结果是不是和刚刚的结果一模一样。
这是因为，我们目前只判断了 $t$ 的根存在，而其存在性 并不能说明 光线与球面的交点 到底是位于摄像机**前面**
_（也就是 $t$ 取正值时）_，还是位于摄像机后面_（也就是 $t$ 取负值时）_。显然这不是_特性_，这是 bug！我们之后会修复这个问题。



表面法向量与多物体
====================================================================================================

利用表面法向量为物体着色
-----------------------------
所谓法向量（surface normal）就是在物体的某一点_（在本例中，光线与物体的交点）_垂直于该点处物体的表面
_（或者本例中，交点处的球面切面）_ 的一个向量。我们可以利用法线为球体着色。_（注意，此处将“法线”和“法向量”混用，但原文亦未做严格区分。——译者）_

但我们要做出一个关键决定：是将法向量归一化（normalize）为单位向量，还是不作这个要求，使之可以取任意长度值？

固然，避免归一化向量中费时的开平方操作是很诱人的（如果我们确实不需要一个单位向量的话）。
但是，在操作中，有以下三个要点值得一提：

    1. 第一，只要有**至少一个**地方要用到单位向量，比起可能用到同一个单位向量时都重新计算一遍，更好的选择显然是一开始就将它计算出来；而实际上，我们**一定**会在**不止一处**用到单位向量；
    2. 第二，在某些几何体的构造函数或者 `hit()` 函数中，计算单位长度的法线向量是很简单的。对球而言，将法线向量除以球半径，就可以将其归一化，并不需要开平方。

综上所述，我们选择将法向量归一化。

对于球面而言，朝向球面外侧的法向量是 光线与球面的交点 与 球心 的向量差值，如下图所示：

    ![Figure [sphere-normal]: 球面的法向量](../images/fig-1.06-sphere-normal.jpg)

以地球为例，你所在的这一点的法向量，就是从地球的球心直直地指向你所在这一点的向量。

现在编写计算法向量的代码。要得到法向量 $\mathbf{n}$，我们需要交点的位置（仅仅知道是否存在交点是不够的）。
由于目前场景中仅仅存在一个被置于相机正前方的球面，如果我们暂时不考虑 $t$ 取负数根的情况，便可以假设 $t$ 最小的根即为所求。

利用计算得到的法向量 $\mathbf{n}$，就可以为我们的球面着色了。
目前我们还没有实现光照等功能，所以我们利用一个色彩映射（color map）来可视化法向量。
经过归一化，法向量的每一个分量都应该取得 -1 到 1 之间的值。
将其每个分量映射到 0 到 1 之间后，再将 $(x, y, z)$ 分别映射为 $(\mathit{red}, \mathit{green}, \mathit{blue})$ 的颜色通道值。

可视化 $\mathbf{n}$ 的代码如下：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    double hit_sphere(const point3& center, double radius, const ray& r) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
        vec3 oc = center - r.origin();
        auto a = dot(r.direction(), r.direction());
        auto b = -2.0 * dot(r.direction(), oc);
        auto c = dot(oc, oc) - radius*radius;
        auto discriminant = b*b - 4*a*c;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        if (discriminant < 0) {
            return -1.0;
        } else {
            return (-b - std::sqrt(discriminant) ) / (2.0*a);
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    }

    color ray_color(const ray& r) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        auto t = hit_sphere(point3(0,0,-1), 0.5, r);
        if (t > 0.0) {
            vec3 N = unit_vector(r.at(t) - vec3(0,0,-1));
            return 0.5*color(N.x()+1, N.y()+1, N.z()+1);
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        vec3 unit_direction = unit_vector(r.direction());
        auto a = 0.5*(unit_direction.y() + 1.0);
        return (1.0-a)*color(1.0, 1.0, 1.0) + a*color(0.5, 0.7, 1.0);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [render-surface-normal]: <kbd>[main.cc]</kbd> 可视化球面法向量]

<div class='together'>
得到以下图像：

    ![<span class='num'>Image 4:</span> 一个基于法向量进行着色的球
    ](../images/img-1.04-normals-sphere.png class='pixel')

</div>


简化计算光线与球面相交的代码
---------------------------------------------
让我们回头看看计算光线与球面相交的函数：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    double hit_sphere(const point3& center, double radius, const ray& r) {
        vec3 oc = center - r.origin();
        auto a = dot(r.direction(), r.direction());
        auto b = -2.0 * dot(r.direction(), oc);
        auto c = dot(oc, oc) - radius*radius;
        auto discriminant = b*b - 4*a*c;

        if (discriminant < 0) {
            return -1.0;
        } else {
            return (-b - std::sqrt(discriminant) ) / (2.0*a);
        }
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [ray-sphere-before]: <kbd>[main.cc]</kbd> 计算光线与球面相交的代码（修改前）]

我们知道，一个向量点乘它自己所得的值，等于它的模长的平方。同时，注意到求得 `b` 的式子中，存在一个系数 -2.


令 $b = -2h$，原始的一元二次方程可以进行如下变化：

    $$ \frac{-b \pm \sqrt{b^2 - 4ac}}{2a} $$

    $$ = \frac{-(-2h) \pm \sqrt{(-2h)^2 - 4ac}}{2a} $$

    $$ = \frac{2h \pm 2\sqrt{h^2 - ac}}{2a} $$

    $$ = \frac{h \pm \sqrt{h^2 - ac}}{a} $$

我们采用这个由原式简化而来的式子。同时我们可以表示出 $h$：

    $$ b = -2 \mathbf{d} \cdot (\mathbf{C} - \mathbf{Q}) $$
    $$ b = -2h $$
    $$ h = \frac{b}{-2} = \mathbf{d} \cdot (\mathbf{C} - \mathbf{Q}) $$

<div class='together'>
由以上计算，我们可以修改原来的代码：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    double hit_sphere(const point3& center, double radius, const ray& r) {
        vec3 oc = center - r.origin();
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        auto a = r.direction().length_squared();
        auto h = dot(r.direction(), oc);
        auto c = oc.length_squared() - radius*radius;
        auto discriminant = h*h - a*c;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        if (discriminant < 0) {
            return -1.0;
        } else {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            return (h - std::sqrt(discriminant)) / a;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
        }
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [ray-sphere-after]: <kbd>[main.cc]</kbd> 计算光线与球面相交的代码（修改后）]

</div>


hittable 抽象类：可被光线命中的物体
------------------------------------
加入更多的球怎么样？固然直接创建一个数组很方便。但是更合理的方法，
应该是创建一个针对任何可以被光线命中的物体的抽象类（abstract class），然后再把“球面”和“一组球面”都当作可以被光线命中的物体。
应该怎么命名这个抽象类呢？叫它 `object` 吧，在面向对象编程（object oriented programming）的语境下又显得有些不妥。
叫它 `surface` 吧，倘若我们以后希望创建一些派生自此抽象类的体积云、体积雾等类，这个名字也显得不太妥当。
`hittable` 强调了它的派生类共有的一个成员函数，即 `hit()`。我们就选定 `hittable` 作为这个抽象类的名称了。

虽然这三个名字我一个都不喜欢。

这个抽象类应当包含接收一个光线作为参数的 `hit` 函数。大多数光追渲染器都会为光线命中设置一个 $t_{\mathit{min}}$ 到 $t_{\mathit{max}}$ 的范围，
只有满足 $t_{\mathit{min}} < t < t_{\mathit{max}}$ 这个范围的光线命中才算数。刚开始的时候，我们只是把 $t$ 的范围限定到了正数，
但是随着我们的进度逐步推进，你便会发现使用 $t_{\mathit{min}} < t < t_{\mathit{max}}$ 这样的一个范围有助于简化代码。
另外一个需要权衡的问题是，是否 只要光线命中某个物体，就计算法向量等数据。因为假如我们这样做，在后续计算中，我们可能会发现光线又击中了离相机更近的一个点，
但是实际上我们只需要距离相机最近的一个点的法向量等数据。

我会将计算得出的各种数据保存在一个类 `hit_record` 里面。以下给出一个简单的示例：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #ifndef HITTABLE_H
    #define HITTABLE_H

    #include "ray.h"

    class hit_record {
    public:
        point3 p;
        vec3 normal;
        double t;
    };

    class hittable {
    public:
        virtual ~hittable() = default;

        virtual bool hit(const ray& r, double ray_tmin, double ray_tmax, hit_record& rec) const = 0;
    };

    #endif
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [hittable-initial]: <kbd>[hittable.h]</kbd> Hittable 抽象类]

<div class='together'>
将球面的实现修改如下：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #ifndef SPHERE_H
    #define SPHERE_H

    #include "hittable.h"
    #include "vec3.h"

    class sphere : public hittable {
      public:
        sphere(const point3& center, double radius) : center(center), radius(std::fmax(0,radius)) {}

        bool hit(const ray& r, double ray_tmin, double ray_tmax, hit_record& rec) const override {
            vec3 oc = center - r.origin();
            auto a = r.direction().length_squared();
            auto h = dot(r.direction(), oc);
            auto c = oc.length_squared() - radius*radius;

            auto discriminant = h*h - a*c;
            if (discriminant < 0)
                return false;

            auto sqrtd = std::sqrt(discriminant);

            // Find the nearest root that lies in the acceptable range.
            auto root = (h - sqrtd) / a;
            if (root <= ray_tmin || ray_tmax <= root) {
                root = (h + sqrtd) / a;
                if (root <= ray_tmin || ray_tmax <= root)
                    return false;
            }

            rec.t = root;
            rec.p = r.at(rec.t);
            rec.normal = (rec.p - center) / radius;

            return true;
        }

      private:
        point3 center;
        double radius;
    };

    #endif
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [sphere-initial]: <kbd>[sphere.h]</kbd> 修改后的球面类]

（在这里我们使用了 C++ 标准库中的 `std::fmax()` 函数，该函数返回两个浮点数参数中较大的一个。
类似地，我们在后面还会见到 `std::fmin()`，它返回两个浮点数参数中较小的一个。）
</div>


判断光线的入射方向
------------------------------
第二个我们要在设计上做出的权衡，则是 是否应该使法向量始终指向面的外侧。目前而言，
我们求得的法向量的方向始终从球心指向交点（指向外）。展开了讲，假如光线在球面的外侧与球面相交，
那么法向量应当与光线入射方向成钝角；假如光线在球面内侧与球面相交，那么法向量应当与光线入射方向成锐角。

但我们也可以让法向量始终与光线入射方向形成钝角。这就是说，如果光线从球面外侧入射，法向量指向球面外；
而光线从球面内侧入射时，法向量转而指向球面内。

    ![Figure [normal-sides]: 光线与球面相交时的可能情况
    ](../images/fig-1.07-normal-sides.jpg)

我们必须从这两个方案中选一个，用以判断光线到底从表面的哪一侧入射。这一判断在渲染某些物体时非常重要：
两侧的材质不同物体，比如一张两面都有字的纸；亦或者是要区分内外的物体，比如玻璃球。

假如我们选择第一个方案，那么在判断光线从哪一侧入射时，我们可以比较光线与法向量的方向，判断依据刚刚已经介绍过了。
具体实现上，可以考虑使用向量点乘：假如点乘所得的值为正数，说明光线从球面内侧入射，反之亦然。


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    if (dot(ray_direction, outward_normal) > 0.0) {
        // ray is inside the sphere
        ...
    } else {
        // ray is outside the sphere
        ...
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [ray-normal-comparison]: 比较光线与法向量的方向关系]

<div class='together'>
假如我们让法向量始终与光线入射方向成钝角，我们就不能用点乘来得到入射的方向了，因此便需要预先把这一方向储存起来。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    bool front_face;
    if (dot(ray_direction, outward_normal) > 0.0) {
        // ray is inside the sphere
        normal = -outward_normal;
        front_face = false;
    } else {
        // ray is outside the sphere
        normal = outward_normal;
        front_face = true;
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [normals-point-against]: 存储光线的入射方向]

</div>

选择哪一种方案，取决于我们想在何时计算入射方向：是在进行相交的几何计算时，还是在着色时？
鉴于本书中关于计算着色的内容多于几何计算，我们选择在计算相交时就求得入射方向，好让计算着色的代码更简洁。
但请注意，这两种方法之间没有孰优孰劣。事实上，采用两种方法的渲染器都存在。

让我们为 `hit_record` 类添加一个布尔型成员 `front_face`，和一个 `set_face_normal()` 方法，用以计算光线入射方向。
为简便，我们假设传递给刚加入的方法传入的向量已经归一化了。当然也可以显式地将向量归一化，但是效率不如在计算相交的时候这么做。


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class hit_record {
    public:
        point3 p;
        vec3 normal;
        double t;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        bool front_face;

        void set_face_normal(const ray& r, const vec3& outward_normal) {
            // Sets the hit record normal vector.
            // NOTE: the parameter `outward_normal` is assumed to have unit length.

            front_face = dot(r.direction(), outward_normal) < 0;
            normal = front_face ? outward_normal : -outward_normal;
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [front-face-tracking]: <kbd>[hittable.h]</kbd> 添加 front-face 成员变量]

<div class='together'>
再在计算光线命中的的方法中，加上判断入射方向的代码：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class sphere : public hittable {
      public:
        ...
        bool hit(const ray& r, double ray_tmin, double ray_tmax, hit_record& rec) const {
            ...

            rec.t = root;
            rec.p = r.at(rec.t);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            vec3 outward_normal = (rec.p - center) / radius;
            rec.set_face_normal(r, outward_normal);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

            return true;
        }
        ...
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [sphere-final]: <kbd>[sphere.h]</kbd> 添加了入射方向判断的球面类]

</div>


hittable_list 类：一个存储多个 hittable 物体的容器
------------------------------------------------
我们已经创建了描述可与光线交互的物体的抽象类 `hittable`。现在添加一个类，用以存储一系列 `hittable`：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #ifndef HITTABLE_LIST_H
    #define HITTABLE_LIST_H

    #include "hittable.h"

    #include <memory>
    #include <vector>

    using std::make_shared;
    using std::shared_ptr;

    class hittable_list : public hittable {
    public:
        std::vector<shared_ptr<hittable>> objects;

        hittable_list() {}
        hittable_list(shared_ptr<hittable> object) { add(object); }

        void clear() { objects.clear(); }

        void add(shared_ptr<hittable> object) {
            objects.push_back(object);
        }

        bool hit(const ray& r, double ray_tmin, double ray_tmax, hit_record& rec) const override {
            hit_record temp_rec;
            bool hit_anything = false;
            auto closest_so_far = ray_tmax;

            for (const auto& object : objects) {
                if (object->hit(r, ray_tmin, closest_so_far, temp_rec)) {
                    hit_anything = true;
                    closest_so_far = temp_rec.t;
                    rec = temp_rec;
                }
            }

            return hit_anything;
        }
    };

    #endif
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [hittable-list-initial]: <kbd>[hittable_list.h]</kbd> hittable_list 类]


一些新的 C++ 特性
----------------------
如果你以前对 C++ 了解较少，`hittable_list` 使用的一些特性可能会让你感到陌生：`vector`，`shared_ptr`，和 `make_shared`：

`shared_ptr<type>` 是一种带有引用计数（reference counting）功能的智能指针，它包含在 `<memory>` 头文件中。每当你将它的值赋给另一个智能指针时，就会让引用计数加一；
当智能指针离开作用域时，引用计数减一。当引用计数归零时，指针被自动释放。

<div class='together'>
一般说来，一个智能指针使用一个新创建的对象初始化，如下代码所示：
    
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    shared_ptr<double> double_ptr = make_shared<double>(0.37);
    shared_ptr<vec3>   vec3_ptr   = make_shared<vec3>(1.414214, 2.718281, 1.618034);
    shared_ptr<sphere> sphere_ptr = make_shared<sphere>(point3(0,0,0), 1.0);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [shared-ptr]: 一个 shared_ptr 的使用案例]
    
</div>

`make_shared<thing>(thing_constructor_params ...)` 使用构造函数参数创建了一个类型 `thing` 的实例，并返回一个 `shared_ptr<thing>`。

<div class='together'>
我们可以使用 `auto` 关键字简化以上的代码：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    auto double_ptr = make_shared<double>(0.37);
    auto vec3_ptr   = make_shared<vec3>(1.414214, 2.718281, 1.618034);
    auto sphere_ptr = make_shared<sphere>(point3(0,0,0), 1.0);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [shared-ptr-auto]: 一个使用了 auto 关键字的 share_ptr 的案例]

</div>

我们之所以要使用智能指针，是因为它可以让几个物体共用某个类型的实例
（比如说，一大堆共享同一个材质的球），同时还可以让内存管理简单便捷。

另一个你可能不太熟悉的 C++ 特性是在头文件 `<vector>` 中的 `std::vector`。它类似于数组，但是它的大小可以随着我们往内添加新的元素而自动增长。
`objects.push_back(object)` 用于向 `vector` 的末尾添加一个 `object`。

最后一点， `using` 声明告诉编译器我们将使用标准库中的 `shared_ptr` 和 `make_shared`，这样我们就不用每次都输入 `std::` 了。


常量和工具函数
---------------------------------------
我们创建一个头文件 `rtweekend.h`，作为一个通用头文件。我们暂时只在里面定义无穷大和之后会用到的圆周率。
以后我们会向里面加入更多的常量和工具函数。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #ifndef RTWEEKEND_H
    #define RTWEEKEND_H

    #include <cmath>
    #include <iostream>
    #include <limits>
    #include <memory>


    // C++ Std Usings

    using std::make_shared;
    using std::shared_ptr;

    // Constants

    const double infinity = std::numeric_limits<double>::infinity();
    const double pi = 3.1415926535897932385;

    // Utility Functions

    inline double degrees_to_radians(double degrees) {
        return degrees * pi / 180.0;
    }

    // Common Headers

    #include "color.h"
    #include "ray.h"
    #include "vec3.h"

    #endif
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [rtweekend-initial]: <kbd>[rtweekend.h]</kbd> rtweekend.h 头文件]

所有的程序代码文件都应首先包含这个头文件，然后其他的头文件都可以假设 `rtweekend.h` 都已经被隐式地被包含了。
但是其他的头文件都应显式地互相包含。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ delete
    #include <iostream>
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [assume-rtw-color]: <kbd>[color.h]</kbd> 假设 color.h 已经包含了 rtweekend.h]


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ delete
    #include "ray.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [assume-rtw-hittable]: <kbd>[hittable.h]</kbd> 假设 hittable.h 已经包含了 rtweekend.h]


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ delete
    #include <memory>
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include <vector>


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ delete
    using std::make_shared;
    using std::shared_ptr;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [assume-rtw-hittable-list]: <kbd>[hittable_list.h]</kbd> 假设 hittable_list.h 已经包含了 rtweekend.h]


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ delete
    #include "vec3.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [assume-rtw-sphere]: <kbd>[sphere.h]</kbd> 假设 sphere.h 已经包含了 rtweekend.h]


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ delete
    #include <cmath>
    #include <iostream>
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [assume-rtw-vec3]: <kbd>[vec3.h]</kbd> 假设 vec3.h 已经包含了 rtweekend.h]


<div class='together'>
现在，我们可以改写主程序代码，再在场景里面添加一个“地面”（其实就是一个很大的球）：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include "rtweekend.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ delete
    #include "color.h"
    #include "ray.h"
    #include "vec3.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include "hittable.h"
    #include "hittable_list.h"
    #include "sphere.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ delete
    #include <iostream>
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ delete
    double hit_sphere(const point3& center, double radius, const ray& r) {
        ...
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    color ray_color(const ray& r, const hittable& world) {
        hit_record rec;
        if (world.hit(r, 0, infinity, rec)) {
            return 0.5 * (rec.normal + color(1,1,1));
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        vec3 unit_direction = unit_vector(r.direction());
        auto a = 0.5*(unit_direction.y() + 1.0);
        return (1.0-a)*color(1.0, 1.0, 1.0) + a*color(0.5, 0.7, 1.0);
    }

    int main() {

        // Image

        auto aspect_ratio = 16.0 / 9.0;
        int image_width = 400;

        // Calculate the image height, and ensure that it's at least 1.
        int image_height = int(image_width / aspect_ratio);
        image_height = (image_height < 1) ? 1 : image_height;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        // World

        hittable_list world;

        world.add(make_shared<sphere>(point3(0,0,-1), 0.5));
        world.add(make_shared<sphere>(point3(0,-100.5,-1), 100));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        // Camera

        auto focal_length = 1.0;
        auto viewport_height = 2.0;
        auto viewport_width = viewport_height * (double(image_width)/image_height);
        auto camera_center = point3(0, 0, 0);

        // Calculate the vectors across the horizontal and down the vertical viewport edges.
        auto viewport_u = vec3(viewport_width, 0, 0);
        auto viewport_v = vec3(0, -viewport_height, 0);

        // Calculate the horizontal and vertical delta vectors from pixel to pixel.
        auto pixel_delta_u = viewport_u / image_width;
        auto pixel_delta_v = viewport_v / image_height;

        // Calculate the location of the upper left pixel.
        auto viewport_upper_left = camera_center
                                 - vec3(0, 0, focal_length) - viewport_u/2 - viewport_v/2;
        auto pixel00_loc = viewport_upper_left + 0.5 * (pixel_delta_u + pixel_delta_v);

        // Render

        std::cout << "P3\n" << image_width << ' ' << image_height << "\n255\n";

        for (int j = 0; j < image_height; j++) {
            std::clog << "\rScanlines remaining: " << (image_height - j) << ' ' << std::flush;
            for (int i = 0; i < image_width; i++) {
                auto pixel_center = pixel00_loc + (i * pixel_delta_u) + (j * pixel_delta_v);
                auto ray_direction = pixel_center - camera_center;
                ray r(camera_center, ray_direction);


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                color pixel_color = ray_color(r, world);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
                write_color(std::cout, pixel_color);
            }
        }

        std::clog << "\rDone.                 \n";
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [main-with-rtweekend-h]: <kbd>[main.cc]</kbd> 新的主程序代码]

</div>

我们得到的图像展示了球面的位置和球面上各个点的法向量。这一方法在检查模型的潜在缺陷时非常好用。

    ![<span class='num'>Image 5:</span> 还是之前那个球，加上了一个“地面”
    ](../images/img-1.05-normals-sphere-ground.png class='pixel')


interval 区间类
------------------
在我们开始做下一步工作之前，先来实现一个用来存储实数区间（interval）的类吧。以后我们会经常用到这个类：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #ifndef INTERVAL_H
    #define INTERVAL_H

    class interval {
    public:
        double min, max;

        interval() : min(+infinity), max(-infinity) {} // Default interval is empty

        interval(double min, double max) : min(min), max(max) {}

        double size() const {
            return max - min;
        }

        bool contains(double x) const {
            return min <= x && x <= max;
        }

        bool surrounds(double x) const {
            return min < x && x < max;
        }

        static const interval empty, universe;
    };

    const interval interval::empty    = interval(+infinity, -infinity);
    const interval interval::universe = interval(-infinity, +infinity);

    #endif
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [interval-initial]: <kbd>[interval.h]</kbd> 区间类]


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    // Common Headers

    #include "color.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include "interval.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include "ray.h"
    #include "vec3.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [interval-rtweekend]: <kbd>[rtweekend.h]</kbd> 包含区间类]


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class hittable {
    public:
        ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        virtual bool hit(const ray& r, interval ray_t, hit_record& rec) const = 0;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [hittable-with-interval]: <kbd>[hittable.h]</kbd> 用区间类重写 hittable::hit()]


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class hittable_list : public hittable {
    public:
        ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        bool hit(const ray& r, interval ray_t, hit_record& rec) const override {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            hit_record temp_rec;
            bool hit_anything = false;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            auto closest_so_far = ray_t.max;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

            for (const auto& object : objects) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                if (object->hit(r, interval(ray_t.min, closest_so_far), temp_rec)) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
                    hit_anything = true;
                    closest_so_far = temp_rec.t;
                    rec = temp_rec;
                }
            }

            return hit_anything;
        }
        ...
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [hittable-list-with-interval]: <kbd>[hittable_list.h]</kbd> 用区间类重写 hittable_list::hit()]


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class sphere : public hittable {
    public:
        ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        bool hit(const ray& r, interval ray_t, hit_record& rec) const override {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            ...

            // Find the nearest root that lies in the acceptable range.
            auto root = (h - sqrtd) / a;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            if (!ray_t.surrounds(root)) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
                root = (h + sqrtd) / a;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                if (!ray_t.surrounds(root))
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
                    return false;
            }
            ...
        }
        ...
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [sphere-with-interval]: <kbd>[sphere.h]</kbd> 用区间类重写球面类]


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    color ray_color(const ray& r, const hittable& world) {
        hit_record rec;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        if (world.hit(r, interval(0, infinity), rec)) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            return 0.5 * (rec.normal + color(1,1,1));
        }

        vec3 unit_direction = unit_vector(r.direction());
        auto a = 0.5*(unit_direction.y() + 1.0);
        return (1.0-a)*color(1.0, 1.0, 1.0) + a*color(0.5, 0.7, 1.0);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [main-with-interval]: <kbd>[main.cc]</kbd> 用区间类重写主程序文件]



把相机封装为一个类
====================================================================================================
我们不妨把相机和渲染相关的代码转移到一个 `camera` 类里面。它主要完成以下两个工作：
  
  1. 创建光线并将它们发射到场景中；
  2. 使用光线计算得到的结果得到渲染图像。

在重构时，把 `ray_color()` 函数和主函数中关于图像、相机模拟，以及渲染的部分全部转移到 `camera` 类型）。
重构后， `camera` 类将包含两个公有方法：`initialize()` 和 `render()`；两个私有方法：`get_ray()` 和 `ray_color()`。

`camera` 类将遵循这样的一个设计模式：使用一个无参构造函数，由使用 `camera` 类的代码自行更改其公有成员变量_（相机的各项参数）_。
相机真正的初始化是通过调用 `initialize()` 函数实现的。为什么不用有参数的构造函数，或者定义一大堆 setter 函数呢？因为：
第一，我们不希望往构造函数内放一大堆参数（其中很多没必要自己设置）；使用现在这种模式，我们只需要显式设置我们需要改变的参数即可。
_（其实可以考虑链式调用模式）_
然后，我们可以在使用 `camera` 的地方调用 `initialize()`，也可以在 `render()` 函数的开头调用。这里选择后一种方案。

最后，我们在程序主函数中创建 `camera` 类的实例，设置各项相机参数，调用 `render()` 方法。实例做好渲染各项准备后即进入渲染循环。

<div class='together'>
这就是 `camera` 类的大致框架：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #ifndef CAMERA_H
    #define CAMERA_H

    #include "hittable.h"

    class camera {
      public:
        /* Public Camera Parameters Here */

        void render(const hittable& world) {
            ...
        }

      private:
        /* Private Camera Variables Here */

        void initialize() {
            ...
        }

        color ray_color(const ray& r, const hittable& world) const {
            ...
        }
    };

    #endif
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [camera-skeleton]: <kbd>[camera.h]</kbd> camera 类的框架]

</div>


<div class='together'>
先填充 `ray_color()` 函数：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class camera {
      ...

      private:
        ...


        color ray_color(const ray& r, const hittable& world) const {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            hit_record rec;

            if (world.hit(r, interval(0, infinity), rec)) {
                return 0.5 * (rec.normal + color(1,1,1));
            }

            vec3 unit_direction = unit_vector(r.direction());
            auto a = 0.5*(unit_direction.y() + 1.0);
            return (1.0-a)*color(1.0, 1.0, 1.0) + a*color(0.5, 0.7, 1.0);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
        }
    };

    #endif
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [camera-ray-color]: <kbd>[camera.h]</kbd> camera::ray_color 方法]

</div>


<div class='together'>
大部分原本属于 `main()` 函数的内容已经被我们悉数迁移到这里了。目前，`main()` 函数中应该只剩下世界场景创建了。
以下为迁移完成后的 `camera` 类的代码：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class camera {
      public:
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        double aspect_ratio = 1.0;  // Ratio of image width over height
        int    image_width  = 100;  // Rendered image width in pixel count

        void render(const hittable& world) {
            initialize();

            std::cout << "P3\n" << image_width << ' ' << image_height << "\n255\n";

            for (int j = 0; j < image_height; j++) {
                std::clog << "\rScanlines remaining: " << (image_height - j) << ' ' << std::flush;
                for (int i = 0; i < image_width; i++) {
                    auto pixel_center = pixel00_loc + (i * pixel_delta_u) + (j * pixel_delta_v);
                    auto ray_direction = pixel_center - center;
                    ray r(center, ray_direction);

                    color pixel_color = ray_color(r, world);
                    write_color(std::cout, pixel_color);
                }
            }

            std::clog << "\rDone.                 \n";
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

      private:
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        int    image_height;   // Rendered image height
        point3 center;         // Camera center
        point3 pixel00_loc;    // Location of pixel 0, 0
        vec3   pixel_delta_u;  // Offset to pixel to the right
        vec3   pixel_delta_v;  // Offset to pixel below

        void initialize() {
            image_height = int(image_width / aspect_ratio);
            image_height = (image_height < 1) ? 1 : image_height;

            center = point3(0, 0, 0);

            // Determine viewport dimensions.
            auto focal_length = 1.0;
            auto viewport_height = 2.0;
            auto viewport_width = viewport_height * (double(image_width)/image_height);

            // Calculate the vectors across the horizontal and down the vertical viewport edges.
            auto viewport_u = vec3(viewport_width, 0, 0);
            auto viewport_v = vec3(0, -viewport_height, 0);

            // Calculate the horizontal and vertical delta vectors from pixel to pixel.
            pixel_delta_u = viewport_u / image_width;
            pixel_delta_v = viewport_v / image_height;

            // Calculate the location of the upper left pixel.
            auto viewport_upper_left =
                center - vec3(0, 0, focal_length) - viewport_u/2 - viewport_v/2;
            pixel00_loc = viewport_upper_left + 0.5 * (pixel_delta_u + pixel_delta_v);
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        color ray_color(const ray& r, const hittable& world) const {
            ...
        }
    };

    #endif
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [camera-working]: <kbd>[camera.h]</kbd> 可以正常工作的 camera 类]

</div>


<div class='together'>
缩减后的主函数：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include "rtweekend.h"


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include "camera.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include "hittable.h"
    #include "hittable_list.h"
    #include "sphere.h"


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ delete
    color ray_color(const ray& r, const hittable& world) {
        ...
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

    int main() {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        hittable_list world;

        world.add(make_shared<sphere>(point3(0,0,-1), 0.5));
        world.add(make_shared<sphere>(point3(0,-100.5,-1), 100));

        camera cam;

        cam.aspect_ratio = 16.0 / 9.0;
        cam.image_width  = 400;

        cam.render(world);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [main-with-new-camera]: <kbd>[main.cc]</kbd> 修改后的主函数]

</div>

运行以上代码得到的渲染结果与之前的一致。



抗锯齿
====================================================================================================
如果放大我们渲染得到的图像，你可能会注意到在物体的边缘上出现了一些陡峭的阶梯状锯齿（aliasing; jaggies）。
一个现实生活中的摄像机拍出的照片里，物体的边缘出现的并非这样的锯齿，而是前景颜色和背景颜色的“混合”。
也就是说，不像我们的渲染图像，现实世界的照片是“连续的”，即具有近乎无限的分辨率。
要近似得到这种效果，可以对每个像素进行多次采样，并取其平均。

在之前的案例中，我们从相机原点向每个像素的中心发射一束光线，这一操作被称为**单点采样**（point sampling）。
但是，这一方法在某些情况下可能出现问题。举例来说，我们要渲染一个位于远处的 8&times;8 的黑白棋盘格。
假设在单点采样的情况下，只有四束光线命中了这个棋盘，这四束光线可能都与白色格子相交，也可能都与黑色格子相交，
还可能是某种乱七八糟的组合。但是在现实生活中，一个远处的棋盘格看起来应该是灰色，而非一堆尖锐的黑白点。
在这里，人眼起到了我们希望渲染器完成的任务：把一个区域内的光线“匀一下”。_（这块翻译简化了）_

很显然，多次采样同一个像素的中心没有任何实际意义。我们想要做的是，先多次采样像素中心**附近**不同的位置，再将得到的结果平均。

考虑以下方案：每次采样时，在像素中心周围 1&times;1 的区域_（说白了就是这个像素内。此处译文和原文表述略有出入）_随机取一个点，
再将所有采样点的结果求平均。这不是最优解，但是是最直接的。
（要了解更多内容，请参阅 [_A Pixel is Not a Little Square_](https://www.researchgate.net/publication/244986797)）

![Figure [pixel-samples]: Pixel samples](../images/fig-1.08-pixel-samples.jpg)


随机数工具
-----------------------------
要实现上面的随机采样功能，需要一个随机数生成器。这个生成器应当返回取值在 $0 ≤ n < 1$ 之间的随机实数。
这个取值范围中的“小于 1”相当重要，以后会用到。

一个简单的方案是使用 `<cstdlib>` 中的 `std::rand()` 函数，该函数返回一个 0 到 `RAND_MAX` 之间的随机值。
在 `rtweekend.h` 中添加以下代码：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include <cmath>
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include <cstdlib>
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include <iostream>
    #include <limits>
    #include <memory>
    ...

    // Utility Functions

    inline double degrees_to_radians(double degrees) {
        return degrees * pi / 180.0;
    }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    inline double random_double() {
        // Returns a random real in [0,1).
        return std::rand() / (RAND_MAX + 1.0);
    }

    inline double random_double(double min, double max) {
        // Returns a random real in [min,max).
        return min + (max-min)*random_double();
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [random-double]: <kbd>[rtweekend.h]</kbd> random_double() 函数]

C++ 最早是没有一个随机数生成器的，好在更新的版本已经解决了这个问题。考虑包含 `<random>` 来使用它。代码如下：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    ...


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include <random>
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

    ...


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    inline double random_double() {
        static std::uniform_real_distribution<double> distribution(0.0, 1.0);
        static std::mt19937 generator;
        return distribution(generator);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

    ...

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [random-double-alt]: <kbd>[rtweekend.h]</kbd> 生成随机数的另一种实现]

**重要：**_我这里特别提一嘴，`mt19937` 生成器需要一个随机种子来初始化。如果不给出随机种子，在某些情况下，生成的随机数会过于雷同，_
_导致出现多物体漫反射产生严重噪声或者大面积瑕疵的现象，即使提高采样数也无法解决，进而影响颜色计算与渲染。——译者_

_在这里给出调整过的代码。_

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    ...


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include <random>
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

    ...


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    inline double random_double() {
        static std::random_device device;
        static std::uniform_real_distribution<double> dist(0.0, 1.0);
        static std::mt19937 gen(device());
        return dist(gen);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

    ...

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [random-double-alt]: <kbd>[rtweekend.h]</kbd> 生成随机数（修改）]


使用多重采样生成图像
----------------------------------------
我们对每个像素都进行多次随机采样，并将所有采样结果求平均，得到该像素的颜色值。

首先更改 `write_color()` 函数，便于我们计算所有采样的平均值。我们每次迭代，
都把前几次迭代加和所得的“颜色值”_（打引号是因为此时某些分量的值可能已经大于 1 了）_，与本次采样所得的颜色值相加。
迭代结束后，再用加和结果除以单个像素的采样数，得到平均值，最后将颜色写入文件。
另外，我们需要保证结果色彩的每个颜色通道值均处于区间 $[0,1]$ 内部，为此我们添加一个小小的工具函数 `interval::clamp(x)`。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class interval {
    public:
        ...

        bool surrounds(double x) const {
            return min < x && x < max;
        }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        double clamp(double x) const {
            if (x < min) return min;
            if (x > max) return max;
            return x;
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
        ...
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [clamp]: <kbd>[interval.h]</kbd> interval::clamp() 工具函数]

用刚刚创建的区间裁剪方法重写的 `write_color()` 函数：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include "interval.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include "vec3.h"

    using color = vec3;

    void write_color(std::ostream& out, const color& pixel_color) {
        auto r = pixel_color.x();
        auto g = pixel_color.y();
        auto b = pixel_color.z();

        // Translate the [0,1] component values to the byte range [0,255].
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        static const interval intensity(0.000, 0.999);
        int rbyte = int(256 * intensity.clamp(r));
        int gbyte = int(256 * intensity.clamp(g));
        int bbyte = int(256 * intensity.clamp(b));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        // Write out the pixel color components.
        out << rbyte << ' ' << gbyte << ' ' << bbyte << '\n';
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [write-color-clamped]: <kbd>[color.h]</kbd> 重写后的 write_color() 函数]

再重写相机类。加入一个 `camera::get_ray(i,j)` 方法，用以生成随机的穿过某个像素的光线。
这个方法又会使用到另一个工具函数 `sample_square()`，此函数会在一个 中心位于原点的 单位边长的 正方形 中随机取一点。
我们通过一些变换，将这个正方形的中心移到我们正在进行采样的像素的中心所在。

<div class="together">
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class camera {
    public:
        double aspect_ratio      = 1.0;  // Ratio of image width over height
        int    image_width       = 100;  // Rendered image width in pixel count
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        int    samples_per_pixel = 10;   // Count of random samples for each pixel
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        void render(const hittable& world) {
            initialize();

            std::cout << "P3\n" << image_width << ' ' << image_height << "\n255\n";

            for (int j = 0; j < image_height; j++) {
                std::clog << "\rScanlines remaining: " << (image_height - j) << ' ' << std::flush;
                for (int i = 0; i < image_width; i++) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                    color pixel_color(0,0,0);
                    for (int sample = 0; sample < samples_per_pixel; sample++) {
                        ray r = get_ray(i, j);
                        pixel_color += ray_color(r, world);
                    }
                    write_color(std::cout, pixel_samples_scale * pixel_color);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
                }
            }

            std::clog << "\rDone.                 \n";
        }
        ...
    private:
        int    image_height;         // Rendered image height
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        double pixel_samples_scale;  // Color scale factor for a sum of pixel samples
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
        point3 center;               // Camera center
        point3 pixel00_loc;          // Location of pixel 0, 0
        vec3   pixel_delta_u;        // Offset to pixel to the right
        vec3   pixel_delta_v;        // Offset to pixel below

        void initialize() {
            image_height = int(image_width / aspect_ratio);
            image_height = (image_height < 1) ? 1 : image_height;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            pixel_samples_scale = 1.0 / samples_per_pixel;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

            center = point3(0, 0, 0);
            ...
        }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        ray get_ray(int i, int j) const {
            // Construct a camera ray originating from the origin and directed at randomly sampled
            // point around the pixel location i, j.

            auto offset = sample_square();
            auto pixel_sample = pixel00_loc
                            + ((i + offset.x()) * pixel_delta_u)
                            + ((j + offset.y()) * pixel_delta_v);

            auto ray_origin = center;
            auto ray_direction = pixel_sample - ray_origin;

            return ray(ray_origin, ray_direction);
        }

        vec3 sample_square() const {
            // Returns the vector to a random point in the [-.5,-.5]-[+.5,+.5] unit square.
            return vec3(random_double() - 0.5, random_double() - 0.5, 0);
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        color ray_color(const ray& r, const hittable& world) const {
            ...
        }
    };

    #endif
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [camera-spp]: <kbd>[camera.h]</kbd> 重写后的相机类]

</div>

在 Github 上的源代码中，除了上面展示的 `sample_square()` 函数，你还能找到一个名叫 `sample_disk` 的函数。
这一函数在本书示例中不会被用到，但是倘若你想要用非方形的像素做些渲染实验，这个函数可以权当一个参考。
此函数还依赖于本书随后要定义的 `random_in_unit_disk()` 函数（参见本书 13.2 节）。

<div class='together'>
更新程序主函数：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    int main() {
        ...

        camera cam;

        cam.aspect_ratio      = 16.0 / 9.0;
        cam.image_width       = 400;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        cam.samples_per_pixel = 100;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        cam.render(world);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [main-spp]: <kbd>[main.cc]</kbd> 规定了每个像素采样次数的主函数]

</div>

<div class='together'>
放大渲染得到的图像，可以看到修改前后有明显的区别：

  ![<span class='num'>Image 6:</span> 抗锯齿前 / 抗锯齿后
  ](../images/img-1.06-antialias-before-after.png class='pixel')

</div>



漫反射材质
====================================================================================================
完成了上面的工作后，我们可以开始做一些看起来更真实的材质了。首先实现漫反射材质（diffuse material），也叫做 _matte_。
开始之前，我们需要在以下两种方案中做出取舍：

    1. 不将材质和特定几何体绑定。（这样便于让多个几何体共享一个材质，或者让一个几何体使用不同的材质）
    2. 将材质和特定几何体绑定。（在生成程序化的几何体时非常有用）

在本书中，我们选择大部分渲染器采用的模式，即前一种。但是切记，可行的方案不止这两种。


一个简单的漫反射材质
--------------------------
具有漫反射材质的物体并不会自己发光。它们一般显现来自环境_（比如说环境光照，或者其它物体的反射光）_的颜色与其本身的颜色的混合。
具有漫反射材质的物体反射光线的方向是随机的。因此，就像下图所示，朝着两个漫反射物体之间的缝隙发射的三束光线，
被表面反射后展现出了完全不同的行为。

    ![Figure [light-bounce]: 光线反射](../images/fig-1.09-light-bounce.jpg)

除了被反射，光线也可能被漫反射材质吸收。材质颜色越暗淡，光线就越可能被吸收。

基本上所有能生成随机方向的算法都可以被用来模拟漫反射。我们从一种最直接的方法开始：对于一束光线，其被漫反射表面反射到各个方向的几率均等。

    ![Figure [random-vec-hor]: 等几率的反射
    ](../images/fig-1.10-random-vec-horizon.jpg)

这是最直白的一种漫反射材质的实现方法。大部分的光追教程（包括本书）都会在给出其它更优方案之前，先介绍本方案。
目前我们还没有一个用来随机反射光线的函数，所以我们现在往 vector 向量类里面添加一点东西。要做的第一件事情是要实现任意向量的生成。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class vec3 {
    public:
        ...

        double length_squared() const {
            return e[0]*e[0] + e[1]*e[1] + e[2]*e[2];
        }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        static vec3 random() {
            return vec3(random_double(), random_double(), random_double());
        }

        static vec3 random(double min, double max) {
            return vec3(random_double(min,max), random_double(min,max), random_double(min,max));
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [vec-rand-util]: <kbd>[vec3.h]</kbd> 生成随机 vec3 的静态方法]

我们要做的第二件事是，确保生成的随机向量可以落在物体表面（在本例中，球面）的指定一侧。
有一些方法符合这一需求，但由于这些方法无论是理解起来还是代码实现都无比复杂，本书不作介绍。
相反，本书选择一种被称作“拒绝采样法”（rejection method）的“笨办法”。此方法的本质是：
不停地生成随机采样，直到某个采样结果符合我们的要求。或者说，“拒绝”错误的采样结果，“接受”正确的结果并将其返回。

可行的方案有很多，其中相对简单的一个如下：

1. 生成一个单位球内的随机向量；
2. 将这个随机向量归一化，以确保其模长等于单位球的半径，也就是 1；
3. 假如归一化后的向量落在球面的指定侧的异侧，则将其方向反转，使其落在球面指定一侧_（指内侧或外侧）_。


<div class='together'>
利用拒绝采样法生成一个单位球内的随机向量的步骤如下：取单位**立方体**（刚好容纳单位球）中的一点（该点的各个坐标都处在 $[0,1]$ 区间内）。
假如这个落到了单位球的外面，就重新取一个点。重复这一过程，直到找到一个位于单位球内部的点，然后构造向量，并将其归一化。

  ![Figure [sphere-vec]: 两个被拒绝的随机向量
  ](../images/fig-1.11-sphere-vec.jpg)

  ![Figure [sphere-vec]: 一个被接受的随机向量及其归一化后的结果
  ](../images/fig-1.12-sphere-unit-vec.jpg)

代码先写个大概：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    ...

    inline vec3 unit_vector(const vec3& v) {
        return v / v.length();
    }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    inline vec3 random_unit_vector() {
        while (true) {
            auto p = vec3::random(-1,1);
            auto lensq = p.length_squared();
            if (lensq <= 1)
                return p / sqrt(lensq);
        }
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [random-in-unit-sphere]: <kbd>[vec3.h]</kbd> random_unit_vector() 函数写个大概版]

</div>

事情还没完呢。浮点数在使用中可能会出现“露底”状况。
_（原文为 abstraction leak，即抽象泄露。译者在这里采用了一个相对浅显<small>实际上还是很迷惑</small>的译法。_
_译者推测，作者想要表达的意思是，在常规情况下，我们使用浮点数的时候不需要了解其背后的实现细节；_
_但是在极个别情况下，比如马上会介绍的案例，浮点数有可能不按照预期工作，这时候我们就必须对其实现细节有一定认识，并进行有针对性的修复。_
_就算你不理解这个名词也没问题，不会对阅读后文造成影响。_
_当然啦，如果你对这个主题感兴趣，也不妨上网搜搜。——译者）_

鉴于浮点数的精度并非无限，当给一个极小的浮点数开平方时，可能发生下溢出（underflow），结果直接变成 0 了。
在本例中，如果生成的向量的三个分量都极其接近于 0，求得的模长可能就变成 0 了。
将 0 用于向量归一化后，得到的是一个长得吓人的假“单位向量” $[\pm\infty, \pm\infty, \pm\infty]$.
为避免发生这种事情，我们把各分量的最小值限定在 $10^{-160}$（对于 64 位的双精度浮点数）。

完善后的函数：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    inline vec3 random_unit_vector() {
        while (true) {
            auto p = vec3::random(-1,1);
            auto lensq = p.length_squared();
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            if (1e-160 < lensq && lensq <= 1)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
                return p / sqrt(lensq);
        }
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [random-in-unit-sphere]: <kbd>[vec3.h]</kbd> 修改过的 random_unit_vector() 函数写个大概版]

<div class='together'>
现在我们得到了一个符合前两项要求的随机单位向量。通过比较这个向量与某表面的法向量，我们可以判断它是否符合第三个要求，即是否位于表面指定的一侧。

![Figure [normal-hor]: 法向量可以帮助我们判断随机向量与指定表面的几何关系
](../images/fig-1.13-surface-normal.jpg)

</div>

<div class='together'>
利用表面法向量与生成的随机向量的点乘结果，可以判断随机向量是否在表面正确的一侧：假如点乘结果为正，在正确的一侧；反之，在错误的一侧，需要将随机向量反向。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    ...

    inline vec3 random_unit_vector() {
        while (true) {
            auto p = vec3::random(-1,1);
            auto lensq = p.length_squared();
            if (1e-160 < lensq && lensq <= 1)
                return p / sqrt(lensq);
        }
    }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    inline vec3 random_on_hemisphere(const vec3& normal) {
        vec3 on_unit_sphere = random_unit_vector();
        if (dot(on_unit_sphere, normal) > 0.0) // In the same hemisphere as the normal
            return on_unit_sphere;
        else
            return -on_unit_sphere;
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [random-in-hemisphere]: <kbd>[vec3.h]</kbd> random_on_hemisphere() 函数]

</div>

如果射向某材质的光线在被反射前后，100% 保持其颜色_（入射光与反射光颜色相同）_，我们就认为这个材质是**白色**的；
假如光线被 100% 吸收_（完全不发生反射）_，我们就认为这个材质是黑色的。
为了演示，我们让 `ray_color` 函数每次计算光线反射，都只返回入射光线颜色值的 50%_（每次反射，表面都吸收 50% 的入射光线）_。
渲染出来，物体应该是灰色。实现代码如下：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class camera {
    ...
    private:
        ...
        color ray_color(const ray& r, const hittable& world) const {
            hit_record rec;

            if (world.hit(r, interval(0, infinity), rec)) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                vec3 direction = random_on_hemisphere(rec.normal);
                return 0.5 * ray_color(ray(rec.p, direction), world);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            }

            vec3 unit_direction = unit_vector(r.direction());
            auto a = 0.5*(unit_direction.y() + 1.0);
            return (1.0-a)*color(1.0, 1.0, 1.0) + a*color(0.5, 0.7, 1.0);
        }
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [ray-color-random-unit]: <kbd>[camera.h]</kbd> 加上了漫反射模拟的 ray_color()]

<div class='together'>
……确实是灰扑扑的一个球：

![<span class='num'>Image 7:</span> 漫反射球面：第一次渲染
](../images/img-1.07-first-diffuse.png class='pixel')

</div>


限制光线反射的次数
----------------------------------
还有一个潜在的问题！<small>_还有完没完了_</small> 相信你已经注意到 `ray_color` 函数是递归的，而递归终止的条件是“如果反射光线没有命中任何物体”。
_看起来合理吗？但是要是光线一直在两个离得很近且角度刁钻的物体之间不停反射呢？_ 在一些情况下，这一过程消耗的运算资源和时间将相当可观。有多可观？
反正调用堆栈溢出和你等渲染结果等红温两件事至少会发生一件。_（原文为 blow the stack，可能玩了一个双关梗：这个短语作为俚语使用时，喻指“使某人发怒”。在这里也指代堆栈溢出）_
为了解决这个问题，我们设置一个最大递归深度：当超出这个深度时，处理为光线消失_（被完全吸收，或者黑色。知乎上有个译版介绍了一个调试技巧，把这个黑色改成别的刺眼的颜色，例如红色，就可以看到哪里在不停发生反射）_。


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class camera {
    public:
        double aspect_ratio      = 1.0;  // Ratio of image width over height
        int    image_width       = 100;  // Rendered image width in pixel count
        int    samples_per_pixel = 10;   // Count of random samples for each pixel
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        int    max_depth         = 10;   // Maximum number of ray bounces into scene
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        void render(const hittable& world) {
            initialize();

            std::cout << "P3\n" << image_width << ' ' << image_height << "\n255\n";

            for (int j = 0; j < image_height; j++) {
                std::clog << "\rScanlines remaining: " << (image_height - j) << ' ' << std::flush;
                for (int i = 0; i < image_width; i++) {
                    color pixel_color(0,0,0);
                    for (int sample = 0; sample < samples_per_pixel; sample++) {
                        ray r = get_ray(i, j);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                        pixel_color += ray_color(r, max_depth, world);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
                    }
                    write_color(std::cout, pixel_samples_scale * pixel_color);
                }
            }

            std::clog << "\rDone.                 \n";
        }
        ...
    private:
        ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        color ray_color(const ray& r, int depth, const hittable& world) const {
            // If we've exceeded the ray bounce limit, no more light is gathered.
            if (depth <= 0)
                return color(0,0,0);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

            hit_record rec;

            if (world.hit(r, interval(0, infinity), rec)) {
                vec3 direction = random_on_hemisphere(rec.normal);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                return 0.5 * ray_color(ray(rec.p, direction), depth-1, world);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            }

            vec3 unit_direction = unit_vector(r.direction());
            auto a = 0.5*(unit_direction.y() + 1.0);
            return (1.0-a)*color(1.0, 1.0, 1.0) + a*color(0.5, 0.7, 1.0);
        }
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [ray-color-depth]: <kbd>[camera.h]</kbd> 带有递归深度限制的 camera::ray_color()]

<div class='together'>
接着更改主函数：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
int main() {
    ...

    camera cam;

    cam.aspect_ratio      = 16.0 / 9.0;
    cam.image_width       = 400;
    cam.samples_per_pixel = 100;
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    cam.max_depth         = 50;
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

    cam.render(world);
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
[Listing [main-ray-depth]: <kbd>[main.cc]</kbd> 更改后的主函数]

</div>

<div class='together'>
对于这个简单的场景，修改前后的差别应该不太明显。

![<span class='num'>Image 8:</span> 漫反射球面：第二次渲染，添加了递归深度限制
](../images/img-1.08-second-diffuse.png class='pixel')

</div>


修复阴影失真问题
-------------------
还有一个小问题！<small>_到底还有几个小问题啊_</small> 在计算光线和球面相交时，计算机会试图得到一个精确的交点位置。
这难道不是好事吗？也许是吧，但是请注意，“试图”得到这个精确值是一码事，能不能得到又是另外一码事了。
之前提到，浮点数的精度是有限的，计算中小数位难免发生舍入，受此影响解得的交点很难做到真正的“精确”。
这进而导致解得的交点位置可能在球面的两侧浮动。如果这个交点浮动到球的内侧，麻烦就大了：由于反射光线会从这个错误的交点发射出去，马上又会从内侧命中这个球面，
这显然不是我们希望得到的情况。但是也不难注意到，如果真的发生这种情况，解得的光束方程中 $t$ 应该取 $0.00000001$ 或者类似的小的不行的数值。
这下好办了，当我们发现 某束反射光线与球面的交点 与 该束光线的原点 距离过近时，舍去_（特殊处理）_这一次反射计算的结果。
_（比如在下面的案例中，就把 不满足范围要求的 那一次反射计算结果 直接设为了背景颜色）_

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class camera {
    ...
    private:
        ...
        color ray_color(const ray& r, int depth, const hittable& world) const {
            // If we've exceeded the ray bounce limit, no more light is gathered.
            if (depth <= 0)
                return color(0,0,0);

            hit_record rec;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            if (world.hit(r, interval(0.001, infinity), rec)) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
                vec3 direction = random_on_hemisphere(rec.normal);
                return 0.5 * ray_color(ray(rec.p, direction), depth-1, world);
            }

            vec3 unit_direction = unit_vector(r.direction());
            auto a = 0.5*(unit_direction.y() + 1.0);
            return (1.0-a)*color(1.0, 1.0, 1.0) + a*color(0.5, 0.7, 1.0);
        }
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [reflect-tolerance]: <kbd>[camera.h]</kbd> 增加了浮点数误差容忍值的反射计算]

<div class='together'>
我们刚刚解决的这个问题被称为阴影失真（shadow acne）。_（亦作“阴影痤疮”。这个术语直译过来就叫这个名）_

    ![<span class='num'>Image 9:</span> 漫反射球面：基本没有阴影失真现象
    ](../images/img-1.09-no-acne.png class='pixel')

</div>


朗伯分布：更好的漫反射模拟方案
--------------------------------
我们之前使用的“向各个方向反射的概率均等”漫反射模型已经可以用于创建相当柔和的漫反射效果了，
但是还有比它更好的方案：**朗伯反射模型**（Lambertian reflection model），或者说**朗伯分布**（Lambertian distribution）。
使用朗伯分布得到的反射光线与 $\cos(\phi)$ 成比例，其中 $\phi$ 是反射光线与表面法向量的夹角。

> 你可能感到有点迷惑，这其实是因为我翻译水平不咋地。文章马上会展开讲，但我先把这个所谓的“成比例”（proportional）的意思解释了。
> 假如光线与球面交点为 $\mathbf{P}$，法向量 $\mathbf{n}$，$\phi$ 是那个夹角。反射光线和法向量的“起点”是同一个点——交点 $\mathbf{P}$.
> 反射光线 $(\mathbf{S}-\mathbf{P})$ 的模长只能是 $2 |\mathbf{n}| cos(\phi)$，不会超出以 $\mathbf{P} + \mathbf{n}$ 为圆心，$2|\mathbf{n}|$ 为半径的圆的范围，就像 Figure [rand-unitvec] 里画的那样。
> ——译者

展开来讲，这意味着反射光线更倾向于朝向与法向量一致的方向，而非与法向量不一致的方向。与我们的手搓算法相比，朗伯分布计算得到的结果会更好。

朗伯算法的本质上是用表面的法向量加上一个随机单位向量。实现朗伯分布的方法如下：

令光线与球面交点为 $\mathbf{p}$，表面法向量 $\mathbf{n}$. 经过 $\mathbf{P}$ 与球面相切的单位球只可能有两个（球面内侧外侧各一个）。
显然，这两个单位球距离球面的距离都是 1，其球心分别位于 $(\mathbf{P} + \mathbf{n})$（对于那个在法向量同侧的）和 $(\mathbf{P} - \mathbf{n})$（对于那个在法向量异侧的）。
前一个单位球在球面的**外面**，后一个单位球在球面的**里面**。_（这里原文说的过分详细了，我自作主张删了一部分。）_

我们选择球面外面那个单位球。在这个球内找一随机点 $\mathbf{S}$，令光线从交点 $\mathbf{P}$ 射向 $\mathbf{S}$（说白了就是构造向量 $(\mathbf{S}-\mathbf{P})$）。

    ![Figure [rand-unitvec]: 朗伯反射示意图
    ](../images/fig-1.14-rand-unitvec.jpg)


<div class='together'>
说了这么多，其实最后要对代码做出的改动没多少：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class camera {
        ...
        color ray_color(const ray& r, int depth, const hittable& world) const {
            // If we've exceeded the ray bounce limit, no more light is gathered.
            if (depth <= 0)
                return color(0,0,0);

            hit_record rec;

            if (world.hit(r, interval(0.001, infinity), rec)) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                vec3 direction = rec.normal + random_unit_vector();
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
                return 0.5 * ray_color(ray(rec.p, direction), depth-1, world);
            }

            vec3 unit_direction = unit_vector(r.direction());
            auto a = 0.5*(unit_direction.y() + 1.0);
            return (1.0-a)*color(1.0, 1.0, 1.0) + a*color(0.5, 0.7, 1.0);
        }
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [ray-color-unit-sphere]: <kbd>[camera.h]</kbd> 使用朗伯分布的 ray_color()]

</div>

<div class='together'>
最后渲染出来的图像好像并没有多大变化：

  ![<span class='num'>Image 10:</span> 使用朗伯分布的漫反射模拟：渲染结果
  ](../images/img-1.10-correct-lambertian.png class='pixel')

</div>

仔细看，其实还是有变化的，只是因为这个场景太简单所以显得不明显：

  1. 阴影显得更真实立体了；
  2. 两个球面都淡淡地染上了天空的蓝色。

这些现象正是 光线的反射模式 由均匀反射 变为了 在法向量附近集中分布 导致的！
具体说来，反射模式改变后，对于球面，射向相机的光线变少
_（原文如此，但是在我们的渲染器实现原理的语境下，这个说法其实不太严谨。你在这里可以直接按照现实中的光线理解）_，它会**变暗**一些；
对于阴影部分，由于更多光线会直直地向上反射，所以在较小的那个球面下面的阴影也会变暗。

之所以我们对漫反射材质在光照下反射光线的模式缺乏直观经验，主要是因为现实生活中没有多少具有理想的漫反射性质的物体。
之后，我们要渲染的场景会越来越复杂，其中都有很多漫反射材质的物体。那时候你可以多多实验不同的漫反射算法的效果，这对你理解他们之间区别的帮助非常大！


伽马矫正：得到亮度正常的图像
----------------------------------------------------
相信你已经注意到，渲染出来的图像非常暗淡。而我们设置的参数是，对于每次反射，球面只吸收 50% 的光线，反射 50% 的光线。
按理说，在现实中，这样的一个物体是非常亮的（呈现很淡的灰色），但渲染结果显然与理论不符。我们可以做个实验：
让漫反射材质的反射率或明度在一个范围内梯度变化，再将所有的图像排列开观察其区别。先把反射率设成 10% （即 0.1 ）吧。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class camera {
        ...
        color ray_color(const ray& r, int depth, const hittable& world) const {
            // If we've exceeded the ray bounce limit, no more light is gathered.
            if (depth <= 0)
                return color(0,0,0);

            hit_record rec;

            if (world.hit(r, interval(0.001, infinity), rec)) {
                vec3 direction = rec.normal + random_unit_vector();
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                return 0.1 * ray_color(ray(rec.p, direction), depth-1, world);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            }

            vec3 unit_direction = unit_vector(r.direction());
            auto a = 0.5*(unit_direction.y() + 1.0);
            return (1.0-a)*color(1.0, 1.0, 1.0) + a*color(0.5, 0.7, 1.0);
        }
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [ray-color-gamut]: <kbd>[camera.h]</kbd> 反射率改为 10% 的 ray_color()]

渲染图像。再设成 30% 反射率，渲染图像。再在反射率设为 50% 70% 90% 时分别渲染。
将结果从左往右依次排开，很显然，图像明度 随反射率梯度增加 也在增加。如下图所示：

    ![<span class='num'>Image 11:</span> The gamut of our renderer so far
    ](../images/img-1.11-linear-gamut.png class='pixel')

你可以仔细看看，或者直接用取色器取色，然后你会发现 50% 反射率的图像比理论上 最亮的图像和最暗的图像的 均值 暗太多了。
反倒是 70% 反射率的图像的颜色更接近那个均值。为什么会这样呢？

这是因为，几乎所有的计算机程序都**假设**图像数据被写入文件前都经过了所谓的**伽马矫正**（gamma correct）。
所谓伽马矫正指的是，在被转化为单字节整数存储前，$[0,1]$ 区间内的小数颜色值先要经过一系列操作，
从所谓的**线性空间**（linear space）变换到**伽马空间**（gamma space）。

图像查看器以为图像数据已经被变换到了伽马空间（实则不然），导致了最终显示的颜色莫名变黑。

将颜色数据变换到伽马空间存储有许多好处，但我们暂时不需要了解那么多，知道存在这么一个问题足矣。
我们选择 “gamma 2” 矫正模式，里面的 “2” 代表：求伽马空间中的值的 2 次方即平方，即可将其变换到线性空间。
我们要进行的是这一过程的逆变换 $1/\mathit{gamma}$，其中 $\mathit{gamma}=2$ ，即给线性空间中的值开平方根。

另外，为了保证程序的鲁棒性（robustness _这个术语的通译就是这样，暂时当作程序的“稳定性”理解就行_），我们特别处理颜色值因为某些原因变为负值的情况。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    inline double linear_to_gamma(double linear_component)
    {
        if (linear_component > 0)
            return std::sqrt(linear_component);

        return 0;
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

    void write_color(std::ostream& out, const color& pixel_color) {
        auto r = pixel_color.x();
        auto g = pixel_color.y();
        auto b = pixel_color.z();


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        // Apply a linear to gamma transform for gamma 2
        r = linear_to_gamma(r);
        g = linear_to_gamma(g);
        b = linear_to_gamma(b);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        // Translate the [0,1] component values to the byte range [0,255].
        static const interval intensity(0.000, 0.999);
        int rbyte = int(256 * intensity.clamp(r));
        int gbyte = int(256 * intensity.clamp(g));
        int bbyte = int(256 * intensity.clamp(b));

        // Write out the pixel color components.
        out << rbyte << ' ' << gbyte << ' ' << bbyte << '\n';
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [write-color-gamma]: <kbd>[color.h]</kbd> 使用伽马矫正的 write_color()]

<div class='together'>
使用了伽马校正后，观察到从暗到明的变化梯度更连贯了：

    ![<span class='num'>Image 12:</span> 经过伽马矫正的明度梯度
    ](../images/img-1.12-gamma-gamut.png class='pixel')

</div>



金属材质
====================================================================================================

为材质创建一个抽象类
-------------------
我们希望不同的物体可以有不同的材质，这时候需要对代码进行一些修改。一种方案是，创建一个各种参数齐活了的万能材质，想用哪些参数就设置哪些参数。
还有一种方案是，创建一个抽象的材质类，用以封装材质的一些独有行为。我个人强推后一种方案。注意到，一个材质需要做的工作主要为以下两项：

  1. 计算并创建散射（反射）光线；（吸收入射光线）
  2. 计算经过反射，光线衰减了多少。

<div class='together'>
代码如下：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #ifndef MATERIAL_H
    #define MATERIAL_H

    #include "hittable.h"

    class material {
      public:
        virtual ~material() = default;

        virtual bool scatter(
            const ray& r_in, const hit_record& rec, color& attenuation, ray& scattered
        ) const {
            return false;
        }
    };

    #endif
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [material-initial]: <kbd>[material.h]</kbd> material 材质抽象类]

</div>


hit_record 类：描述光线-物体相交 的数据结构
---------------------------------------------
如果你乐意的话，传一大堆参数描述光线-物体相交也行，但是这样不太好。不妨创建一个 `hit_record` 类，用来描述光线与物体的相交，从而简化传参。
_（这其实是一种很有效的设计模式，而且便于后期新增功能或者重构 _
`hittable` 类和 `material` 类无可避免地需要互相引用。因此我们在 `hittable` 类的头文件内预先写一行 `class material;` 告诉编译器 `material` 过一会就会定义。
又因为我们只是要在这个头文件里面使用 `material` 声明一个指针，作为 `hit_record` 类的成员变量，因此编译器不需要知道 `material` 类的实现细节，从而解决了循环引用的问题。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    class material;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

    class hit_record {
    public:
        point3 p;
        vec3 normal;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        shared_ptr<material> mat;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
        double t;
        bool front_face;

        void set_face_normal(const ray& r, const vec3& outward_normal) {
            front_face = dot(r.direction(), outward_normal) < 0;
            normal = front_face ? outward_normal : -outward_normal;
        }
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [hit-with-material]: <kbd>[hittable.h]</kbd> hit_record 类，添加了一个 material 智能指针]

当光线命中某个表面（比如一个球面）时，一个 `hit_record` 类的实例中的 材质指针 就会指向 那个球面的材质。（球面的材质在我们创建球面时设置）
当 `ray_color()` 得到 `hit_record` 后，它就可以调用球面的材质的方法，从而获得反射光线的各项数据（如果有的话）。


<div class='together'>
要实现上述功能，球面需要“告知” `hit_record` 它的材质。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class sphere : public hittable {
      public:
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        sphere(const point3& center, double radius) : center(center), radius(std::fmax(0,radius)) {
            // TODO: Initialize the material pointer `mat`.
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        bool hit(const ray& r, interval ray_t, hit_record& rec) const override {
            ...

            rec.t = root;
            rec.p = r.at(rec.t);
            vec3 outward_normal = (rec.p - center) / radius;
            rec.set_face_normal(r, outward_normal);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            rec.mat = mat;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

            return true;
        }

      private:
        point3 center;
        double radius;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        shared_ptr<material> mat;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [sphere-material]: <kbd>[sphere.h]</kbd> 球面与光线相交计算，添加了额外的材质信息]

</div>


建立光线散射和反射的模型
----------------------
现在介绍一个本书会多次用到的概念——“反照率”（albedo，拉丁语的“白度”）。
在某些专业领域中，反照率是一个精确的术语。但这一术语也可以被用于定义某种**区域反射率**（fractional reflectance）。
反照率除了会受到材质颜色的影响，有时还会受到观察方向（入射光线的方向 _还记得这里所谓的“光线”的实质吗？_）影响。（例如在之后会实现的玻璃材质里面）

现在开始建立不同类型的反射模型。

朗伯反射模型的实现可以选择以下方案，其中反射率为 $R$：

  1. 光线总是既散射又衰减，每次反射都让光线衰减为原来的 $R$；
  2. 有 $R$ 的几率只使光线散射而不衰减，另有 $1-R$ 的几率使光线被完全吸收。_（注意，此处译文与原文有较大出入）_

也可以混合使用这两种方案。我们选择实现起来相对简单的第一个方案。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class material {
        ...
    };


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    class lambertian : public material {
    public:
        lambertian(const color& albedo) : albedo(albedo) {}

        bool scatter(const ray& r_in, const hit_record& rec, color& attenuation, ray& scattered)
        const override {
            auto scatter_direction = rec.normal + random_unit_vector();
            scattered = ray(rec.p, scatter_direction);
            attenuation = albedo;
            return true;
        }

    private:
        color albedo;
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [lambertian-initial]: <kbd>[material.h]</kbd> 朗伯反射材质类]

另外还有一种方案：光线有 $p$ 的固定几率被衰减并散射，同时把衰减率 `attenuation` 设成 $\mathit{albedo}/p$；另有 $1-p$ 的几率光线被完全吸收（黑色）
_（这三种方案的底层逻辑似乎是类似的——这是我的臆测，仅供参考。——译者）_

你要是认真读了上面的代码，应该会注意到一个漏洞：如果生成的随机单位向量与法向量完全相反，它们的加和就会变成零向量，进而导致非常严重的后果（计算得到无穷大或者非数字 NaN ）。
我们需要特别处理这种情况。

创建一个 `vec3` 类的方法 `vec3::near_zero()`。假如某个向量的所有分量均十分接近 0 时，方法返回真；否则，方法返回假。

以下的代码会用到 C++ 标准库中的函数 `std::fabs`，此函数用于求浮点数的绝对值。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class vec3 {
        ...

        double length_squared() const {
            return e[0]*e[0] + e[1]*e[1] + e[2]*e[2];
        }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        bool near_zero() const {
            // Return true if the vector is close to zero in all dimensions.
            auto s = 1e-8;
            return (std::fabs(e[0]) < s) && (std::fabs(e[1]) < s) && (std::fabs(e[2]) < s);
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        ...
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [vec3-near-zero]: <kbd>[vec3.h]</kbd> vec3::near_zero() 方法]


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class lambertian : public material {
    public:
        lambertian(const color& albedo) : albedo(albedo) {}

        bool scatter(const ray& r_in, const hit_record& rec, color& attenuation, ray& scattered)
        const override {
            auto scatter_direction = rec.normal + random_unit_vector();


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            // Catch degenerate scatter direction
            if (scatter_direction.near_zero())
                scatter_direction = rec.normal;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

            scattered = ray(rec.p, scatter_direction);
            attenuation = albedo;
            return true;
        }

    private:
        color albedo;
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [lambertian-catch-zero]: <kbd>[material.h]</kbd> 基本不会再捅篓子的朗伯反射材质]


镜面反射
--------------------------
抛光的金属表面并不会像漫反射表面那样随机地散射入射光线。问题来了：金属表面如何反射光线？仍然可以使用向量进行推导。

    ![Figure [reflection]: 光线的反射](../images/fig-1.15-reflection.jpg)

不难发现红色的反射光线其实就是 $\mathbf{v} + 2\mathbf{b}$。在我们这里，$\mathbf{n}$ 是一个单位向量，但是$\mathbf{v}$ 不一定是。
首先需要把 $\mathbf{n}$ 的长度扩大为 $\mathbf{v}$ 在 $\mathbf{n}$ 上的投影长的绝对值。
容易看出，投影长绝对值由 $\mathbf{v}$ 和 $\mathbf{n}$ 的点乘结果**取反**得到（两个向量成钝角！），点乘结果乘上 $\mathbf{n}$，
进而得到放大后的 $\mathbf{b}$。再用<br/>入射光线 $\mathbf{v}$ 加上两个 $\mathbf{b}$ 即可得到反射光线的方向。

代码如下：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    ...

    inline vec3 random_on_hemisphere(const vec3& normal) {
        ...
    }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    inline vec3 reflect(const vec3& v, const vec3& n) {
        return v - 2*dot(v,n)*n;
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [vec3-reflect]: <kbd>[vec3.h]</kbd> vec3 镜面反射计算 内联函数]

<div class='together'>
利用这个内联函数，很容易编写金属材质反射光线的逻辑：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    ...

    class lambertian : public material {
        ...
    };


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    class metal : public material {
    public:
        metal(const color& albedo) : albedo(albedo) {}

        bool scatter(const ray& r_in, const hit_record& rec, color& attenuation, ray& scattered)
        const override {
            vec3 reflected = reflect(r_in.direction(), rec.normal);
            scattered = ray(rec.p, reflected);
            attenuation = albedo;
            return true;
        }

    private:
        color albedo;
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [metal-material]: <kbd>[material.h]</kbd> 金属材质，使用反射计算内联函数]

</div>

<div class='together'>
修改 `ray_color()` 函数：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include "hittable.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include "material.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    ...

    class camera {
    ...
    private:
        ...
        color ray_color(const ray& r, int depth, const hittable& world) const {
            // If we've exceeded the ray bounce limit, no more light is gathered.
            if (depth <= 0)
                return color(0,0,0);

            hit_record rec;

            if (world.hit(r, interval(0.001, infinity), rec)) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                ray scattered;
                color attenuation;
                if (rec.mat->scatter(r, rec, attenuation, scattered))
                    return attenuation * ray_color(scattered, depth-1, world);
                return color(0,0,0);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            }

            vec3 unit_direction = unit_vector(r.direction());
            auto a = 0.5*(unit_direction.y() + 1.0);
            return (1.0-a)*color(1.0, 1.0, 1.0) + a*color(0.5, 0.7, 1.0);
        }
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [ray-color-scatter]: <kbd>[camera.h]</kbd> 修改后的 ray_color() 函数]

</div>


一个加入了金属球的场景
----------------------
往场景里加入金属球：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include "rtweekend.h"

    #include "camera.h"
    #include "hittable.h"
    #include "hittable_list.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include "material.h"
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include "sphere.h"

    int main() {
        hittable_list world;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        auto material_ground = make_shared<lambertian>(color(0.8, 0.8, 0.0));
        auto material_center = make_shared<lambertian>(color(0.1, 0.2, 0.5));
        auto material_left   = make_shared<metal>(color(0.8, 0.8, 0.8));
        auto material_right  = make_shared<metal>(color(0.8, 0.6, 0.2));

        world.add(make_shared<sphere>(point3( 0.0, -100.5, -1.0), 100.0, material_ground));
        world.add(make_shared<sphere>(point3( 0.0,    0.0, -1.2),   0.5, material_center));
        world.add(make_shared<sphere>(point3(-1.0,    0.0, -1.0),   0.5, material_left));
        world.add(make_shared<sphere>(point3( 1.0,    0.0, -1.0),   0.5, material_right));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        camera cam;

        cam.aspect_ratio      = 16.0 / 9.0;
        cam.image_width       = 400;
        cam.samples_per_pixel = 100;
        cam.max_depth         = 50;

        cam.render(world);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [scene-with-metal]: <kbd>[main.cc]</kbd> 加入了金属球的场景]

<div class='together'>
输出以下图像：

    ![<span class='num'>Image 13:</span> 闪亮的金属球
    ](../images/img-1.13-metal-shiny.png class='pixel')

</div>


模糊反射
---------
可以试着给反射方向加上一点随机。用原本的反射光线的方向向量，再加上一个随机三维向量与模糊系数（fuzz factor）的乘积，就可以使反射光线发生微小的偏移。
如下图所示：

    ![Figure [reflect-fuzzy]: Generating fuzzed reflection rays](../images/fig-1.16-reflect-fuzzy.jpg)

显然，模糊系数越大，随机向量的随机范围就越大，反射光线发生的偏移也会越大。或者说，所有可能的随机向量构成的球“fuzz”的半径就会越大。
如果这个随机范围太大了，反射光线可能跑到发生镜面反射的球面内部。此时，我们假设光线被球面吸收了即可。

另外，特别注意，我们最好先把反射光线的方向向量归一化，好让随机向量对不同的反射光线起到的“模糊”作用一致。
毕竟，我们计算出来的反射方向向量有长有短，但是随机向量的随机范围却是固定的。如果不进行归一化，两个长度不同的反射方向向量，哪怕是加上同样的一个随机向量，得到的也是不同的偏移效果。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class metal : public material {
    public:
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        metal(const color& albedo, double fuzz) : albedo(albedo), fuzz(fuzz < 1 ? fuzz : 1) {}
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        bool scatter(const ray& r_in, const hit_record& rec, color& attenuation, ray& scattered)
        const override {
            vec3 reflected = reflect(r_in.direction(), rec.normal);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            reflected = unit_vector(reflected) + (fuzz * random_unit_vector());
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            scattered = ray(rec.p, reflected);
            attenuation = albedo;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            return (dot(scattered.direction(), rec.normal) > 0);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
        }

    private:
        color albedo;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        double fuzz;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [metal-fuzz]: <kbd>[material.h]</kbd> 实现模糊的金属材质]

<div class='together'>
可以看看模糊系数为 0.3 和 1.0 的金属呈现出的效果：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    int main() {
        ...
        auto material_ground = make_shared<lambertian>(color(0.8, 0.8, 0.0));
        auto material_center = make_shared<lambertian>(color(0.1, 0.2, 0.5));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        auto material_left   = make_shared<metal>(color(0.8, 0.8, 0.8), 0.3);
        auto material_right  = make_shared<metal>(color(0.8, 0.6, 0.2), 1.0);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
        ...
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [metal-fuzz-spheres]: <kbd>[main.cc]</kbd> 创建模糊的金属球]

    ![<span class='num'>Image 14:</span> 模糊的金属材质：渲染结果
    ](../images/img-1.14-metal-fuzz.png class='pixel')

</div>


透明介质
====================================================================================================

> 部分早期译版将此节标题单词 dielectric 译为“绝缘体”，但本人认为此翻译实在过于牵强，未延续使用。
> 鉴于 dielectric 还有一个翻译是“电介质”，可以合理推测作者在这里可能想表示“光介质”之义。
> 因此本人最后取“介质”的译法。——译者

透明的物体，例如水、玻璃与金刚石都是介质。当一束光命中此类介质的时候，会一分为两束：一束反射光线与一束折射（refracted）光线。
由于我们一次只能生成一束偏折光线，所以每次命中时，我们在反射和折射中随机选一种情况进行计算。

**反射光线**的性质：光线命中介质表面后，“反弹”到另一个方向；

**折射光线**的性质：光线命中介质表面后，并不反弹到别的方向，而是发生一定的弯折，进入介质（比如玻璃或者水）内部。举例来说，放在水里的铅笔看起来变弯，就是因为折射。

介质对光线的偏折能力，被量化为介质的**折射率**（refractive index）。这个值描述了光线从真空进入某介质时偏折的程度。
玻璃的折射率大概是 1.5&dash;1.7，金刚石的大概是 2.4，空气的折射率则仅为 1.000293。

光线从一种介质进入另一介质时，光线的偏折程度取决于“相对折射率”（relative refraction index）。相对折射率可以由某介质的折射率除以它周围环境介质的折射率得到。
例如，对于一个泡在水里的玻璃球，相对折射率就是玻璃的折射率 1.5 除以水的折射率 1.333，大致等于 1.125._（注意，作者在此并未特别区别光密介质和光疏介质）_

大部分常见材质的折射率都可以在网上搜到。


折射
---------
调试起来最麻烦的一个部分就是折射了。在一开始我们只允许光线在透明介质处发生折射_（而非同时发生折射和反射）_。
我先试着在场景里面放了两个玻璃球，得到了下面的图像：

    ![<span class='num'>Image 15:</span> 玻璃球
    ](../images/img-1.15-glass-first.png class='pixel')

虽然说现实生活中可能看不到太多规规矩矩的玻璃球，但我们也能明显的感觉到这张图错了：首先从玻璃球里看到的图像应该上下翻转；
其次也不应该有莫名其妙的黑色边框出现。渲染这张图像的时候，我用了一个显然错误的方法：只是让光线直直的穿过这些“玻璃球”。
要得到正确的结果，我们需要进行合理的反射和折射计算。


折射定律
---------
折射的规律可以由折射定律（或者斯涅尔定律，Snell's law）定量描述：

    $$ \eta \cdot \sin\theta = \eta' \cdot \sin\theta' $$

其中，$\theta$ 和 $\theta'$ 为光线与法线所成夹角，$\eta$ 和 $\eta'$ 为折射率。

    ![Figure [refraction]: 光线折射](../images/fig-1.17-refraction.jpg)

要知道折射光线的方向，必须解得 $\sin\theta'$，如下：

    $$ \sin\theta' = \frac{\eta}{\eta'} \cdot \sin\theta $$

在反射光线的一侧，有一束反射光线 $\mathbf{R'}$ 和一个法向量 $\mathbf{n'}$，它们之间构成一个夹角 $\theta'$。
我们可以把 $\mathbf{R'}$ 分解成 平行于 和 垂直于 $\mathbf{n'}$ 的向量各一个。

    $$ \mathbf{R'} = \mathbf{R'}_{\bot} + \mathbf{R'}_{\parallel} $$

利用几何关系，求解 $\mathbf{R'}_{\bot}$ 和 $\mathbf{R'}_{\parallel}$ 得到：

    $$ \mathbf{R'}_{\bot} = \frac{\eta}{\eta'} (\mathbf{R} + \cos\theta \mathbf{n}) $$
    $$ \mathbf{R'}_{\parallel} = -\sqrt{1 - |\mathbf{R'}_{\bot}|^2} \mathbf{n} $$

你可以自己试着证明一下，但是证明不出来也无所谓，尽管把这个结论拿去用就行了。
理解本书的其余部分并不需要你知道这个结论的证明方法。

除了 $\cos\theta$ 以外的等式右侧的值都已知。而我们知道，两个向量的点乘可以写成下式这样：

    $$ \mathbf{a} \cdot \mathbf{b} = |\mathbf{a}| |\mathbf{b}| \cos\theta $$

倘若我们把向量 $\mathbf{a}$ 和 $\mathbf{b}$ 限定为单位向量，那么有：

    $$ \mathbf{a} \cdot \mathbf{b} = \cos\theta $$

现在，已经可以求得 $\mathbf{R'}_{\bot}$ 的值了：

    $$ \mathbf{R'}_{\bot} =
    \frac{\eta}{\eta'} (\mathbf{R} + (\mathbf{-R} \cdot \mathbf{n}) \mathbf{n}) $$

<div class='together'>
由上面的数学推导，可以写出一个计算 $\mathbf{R'}$ 的函数：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    ...

    inline vec3 reflect(const vec3& v, const vec3& n) {
        return v - 2*dot(v,n)*n;
    }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    inline vec3 refract(const vec3& uv, const vec3& n, double etai_over_etat) {
        auto cos_theta = std::fmin(dot(-uv, n), 1.0);
        vec3 r_out_perp =  etai_over_etat * (uv + cos_theta*n);
        vec3 r_out_parallel = -std::sqrt(std::fabs(1.0 - r_out_perp.length_squared())) * n;
        return r_out_perp + r_out_parallel;
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [refract]: <kbd>[vec3.h]</kbd> 计算折射的函数]

</div>

<div class='together'>
透明介质材质（暂时只会发生折射，不会发生反射）：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    ...

    class metal : public material {
        ...
    };


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    class dielectric : public material {
      public:
        dielectric(double refraction_index) : refraction_index(refraction_index) {}

        bool scatter(const ray& r_in, const hit_record& rec, color& attenuation, ray& scattered)
        const override {
            attenuation = color(1.0, 1.0, 1.0);
            double ri = rec.front_face ? (1.0/refraction_index) : refraction_index;

            vec3 unit_direction = unit_vector(r_in.direction());
            vec3 refracted = refract(unit_direction, rec.normal, ri);

            scattered = ray(rec.p, refracted);
            return true;
        }

      private:
        // Refractive index in vacuum or air, or the ratio of the material's refractive index over
        // the refractive index of the enclosing media
        double refraction_index;
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [dielectric-always-refract]: <kbd>[material.h]</kbd> 透明介质材质]

</div>

<div class='together'>
现在我们把最左边的那个球体的材质设成玻璃（折射率大约为 1.5 ）来测试反射。

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    auto material_ground = make_shared<lambertian>(color(0.8, 0.8, 0.0));
    auto material_center = make_shared<lambertian>(color(0.1, 0.2, 0.5));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    auto material_left   = make_shared<dielectric>(1.50);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    auto material_right  = make_shared<metal>(color(0.8, 0.6, 0.2), 1.0);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [two-glass]: <kbd>[main.cc]</kbd> 把左边的球设成玻璃材质]

</div>

<div class='together'>
渲染得到以下结果：

  ![<span class='num'>Image 16:</span> 只会发生折射的玻璃球
  ](../images/img-1.16-glass-always-refract.png class='pixel')

</div>


内全反射
---------
有一个问题是，在某些情况下，使用折射定律无法解得折射角。当一束光线从光密介质（折射率相对较大的介质）射入光疏介质（折射率相对较小的介质）时，
如果入射角足够大，它就会以一个大于 90&deg; 的角折射。再看看是如何计算 $\sin\theta'$ 的吧：

    $$ \sin\theta' = \frac{\eta}{\eta'} \cdot \sin\theta $$

假如光线从玻璃（$\eta = 1.5$）射向空气（$\eta = 1.0$）：

    $$ \sin\theta' = \frac{1.5}{1.0} \cdot \sin\theta $$

<div class='together'>
$\sin\theta'$ 的值不能比 1 大。因此，如果有：

    $$ \frac{1.5}{1.0} \cdot \sin\theta > 1.0 $$

现在你是无法解得一个 $\sin\theta'$ 的。如果折射无法发生，那么就只能发生反射了：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    if (ri * sin_theta > 1.0) {
        // Must Reflect
        ...
    } else {
        // Can Refract
        ...
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [dielectric-can-refract-1]: <kbd>[material.h]</kbd> 判断光线是否能发生折射]

</div>

在这种情况下，由于不发生折射，光线完全被反射。又因为这种现象往往在物体的内部发生，所以它被称为**内全反射**（total internal reflection）
一个例子就是，当你在水面下垂直地看向水面时，可以看到水面上的物体；但是当你接近水面，并且实现和水面夹角比较小的时候，会发现水面像镜子一样反光。

利用三角函数的性质很容易解得 `sin_theta`：

    $$ \sin\theta  = \sqrt{1 - \cos^2\theta} $$

然后：

    $$ \cos\theta = \mathbf{R} \cdot \mathbf{n} $$

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    double cos_theta = std::fmin(dot(-unit_direction, rec.normal), 1.0);
    double sin_theta = std::sqrt(1.0 - cos_theta*cos_theta);

    if (ri * sin_theta > 1.0) {
        // Must Reflect
        ...
    } else {
        // Can Refract
        ...
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [dielectric-can-refract-2]: <kbd>[material.h]</kbd> 判断光线能否发生折射]


<div class='together'>
一个只会发生折射（或者内全反射）的透明介质材质：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class dielectric : public material {
      public:
        dielectric(double refraction_index) : refraction_index(refraction_index) {}

        bool scatter(const ray& r_in, const hit_record& rec, color& attenuation, ray& scattered)
        const override {
            attenuation = color(1.0, 1.0, 1.0);
            double ri = rec.front_face ? (1.0/refraction_index) : refraction_index;

            vec3 unit_direction = unit_vector(r_in.direction());
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            double cos_theta = std::fmin(dot(-unit_direction, rec.normal), 1.0);
            double sin_theta = std::sqrt(1.0 - cos_theta*cos_theta);

            bool cannot_refract = ri * sin_theta > 1.0;
            vec3 direction;

            if (cannot_refract)
                direction = reflect(unit_direction, rec.normal);
            else
                direction = refract(unit_direction, rec.normal, ri);

            scattered = ray(rec.p, direction);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            return true;
        }

      private:
        // Refractive index in vacuum or air, or the ratio of the material's refractive index over
        // the refractive index of the enclosing media
        double refraction_index;
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [dielectric-with-refraction]: <kbd>[material.h]</kbd> 加入了内全反射判断的透明介质材质]

</div>

光线不会发生衰减，所以衰减率恒为 1._（注意一下，这个所谓的“衰减率”为 1 时才是不衰减，0 才是完全吸收。要是糊涂了请复习一下 `ray_color()` 的逻辑）_

现在，重新渲染图像……好像没有变化？为什么？

我们给了透明的球一个比空气大的折射率，因此没有任何一个入射角可以导致内全反射发生——不管是光线进入球的入射角，还是光线从球射出时的入射角。
这和球的几何性质有关：进入球体时，入射光线会被偏折为一个更小的角；从球体出射时，又会被偏折为和入射时相同的角。

那怎么才能渲染得到内全反射现象呢？如果球体的折射率比它所在的介质的折射率**还要小**，然后当角度合适时，就会发生**外全反射**（external total reflection）。
这样也勉强算是看到了吧。

假设现在，我们的世界环境中充满了水（折射率约为 1.33），然后把球设成空气（折射率大约为 1.00）——一个在水里的空气泡。现在能计算得到左边那个球的折射率：

    $$\frac{\text{index of refraction of air}}{\text{index of refraction of water}}$$

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    auto material_ground = make_shared<lambertian>(color(0.8, 0.8, 0.0));
    auto material_center = make_shared<lambertian>(color(0.1, 0.2, 0.5));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    auto material_left   = make_shared<dielectric>(1.00 / 1.33);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    auto material_right  = make_shared<metal>(color(0.8, 0.6, 0.2), 1.0);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [two-glass]: <kbd>[main.cc]</kbd> 左边的球相当于变成了一个气泡]

>
> 知乎上的一个译版给出了一个技巧：把玻璃球的半径设为一个**负数**，这样在不改变球的大小的同时，可以将球的法向量翻转，从而得到一个通透的玻璃球。
>

<div class='together'>
渲染得到以下结果：

  ![<span class='num'>Image 17:</span> 有时候反射光线，有时候折射光线的气泡
  ](../images/img-1.17-air-bubble-total-reflection.png class='pixel')

大部分直接射向球的光线发生折射，而那些和球面所成角度刁钻的光线就发生反射了。

</div>


Schlick 近似
--------------
现在我们的材质已经有了类似现实生活中透明材质的特性了：可以发生折射，在角度足够大时候发生反射。
但是实现这样的效果需要一大堆又臭又长的公式。所幸 Christophe Schlick 发明了一种又快又好又简洁的估计法，
这一方法也为绝大多数人所使用。修改后代码如下：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class dielectric : public material {
    public:
        dielectric(double refraction_index) : refraction_index(refraction_index) {}

        bool scatter(const ray& r_in, const hit_record& rec, color& attenuation, ray& scattered)
        const override {
            attenuation = color(1.0, 1.0, 1.0);
            double ri = rec.front_face ? (1.0/refraction_index) : refraction_index;

            vec3 unit_direction = unit_vector(r_in.direction());
            double cos_theta = std::fmin(dot(-unit_direction, rec.normal), 1.0);
            double sin_theta = std::sqrt(1.0 - cos_theta*cos_theta);

            bool cannot_refract = ri * sin_theta > 1.0;
            vec3 direction;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            if (cannot_refract || reflectance(cos_theta, ri) > random_double())
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
                direction = reflect(unit_direction, rec.normal);
            else
                direction = refract(unit_direction, rec.normal, ri);

            scattered = ray(rec.p, direction);
            return true;
        }

    private:
        // Refractive index in vacuum or air, or the ratio of the material's refractive index over
        // the refractive index of the enclosing media
        double refraction_index;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        static double reflectance(double cosine, double refraction_index) {
            // Use Schlick's approximation for reflectance.
            auto r0 = (1 - refraction_index) / (1 + refraction_index);
            r0 = r0*r0;
            return r0 + (1-r0)*std::pow((1 - cosine),5);
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [glass]: <kbd>[material.h]</kbd> 透明介质材质：完整实现]


创建一个空心的玻璃球
---------------------
来试着创建一个空心的玻璃球吧。说白了就是有大小两个球面套在一起，大的那个球材质不是空气，小的那个球材质是空气。
一束光线会先后命中大球外表面、小球外表面、小球内表面、大球内表面，每次命中都发生折射，最后回到周围环境。

大球的折射率设为 玻璃与外层空气的 相对折射率 1.5 ，内侧的球的折射率设为 **空气与球的相对折射率**，以此模拟从玻璃材质进入空气时的现象。
应该不难理解，因为透明介质材质的参数 `refraction_index` 其实可以被理解为 一个物体的折射率 与 这个物体周围的介质的折射率 的**比值。
因此，内层球的折射率应该为 空气（内层球本身）的折射率比上玻璃（包裹着内层球的介质）的折射率之比，也就是 $1.00/1.50 = 0.67$.

代码如下：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    ...
    auto material_ground = make_shared<lambertian>(color(0.8, 0.8, 0.0));
    auto material_center = make_shared<lambertian>(color(0.1, 0.2, 0.5));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    auto material_left   = make_shared<dielectric>(1.50);
    auto material_bubble = make_shared<dielectric>(1.00 / 1.50);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    auto material_right  = make_shared<metal>(color(0.8, 0.6, 0.2), 0.0);

    world.add(make_shared<sphere>(point3( 0.0, -100.5, -1.0), 100.0, material_ground));
    world.add(make_shared<sphere>(point3( 0.0,    0.0, -1.2),   0.5, material_center));
    world.add(make_shared<sphere>(point3(-1.0,    0.0, -1.0),   0.5, material_left));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    world.add(make_shared<sphere>(point3(-1.0,    0.0, -1.0),   0.4, material_bubble));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    world.add(make_shared<sphere>(point3( 1.0,    0.0, -1.0),   0.5, material_right));
    ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [scene-hollow-glass]: <kbd>[main.cc]</kbd> 为场景添加一个空心的玻璃球]

<div class='together'>
渲染得到以下结果：

![<span class='num'>Image 18:</span> 空心玻璃球：渲染结果
](../images/img-1.18-glass-hollow.png class='pixel')

</div>



可以移动的相机
====================================================================================================
调试相机和调试透明介质材质一样令人头大，所以我一般都选择逐步实现相机功能，而非一蹴而就。
首先，让我们实现一个可调节的**视场角**（field of view; fov）功能。
所谓视场角，指的是 从相机可见范围内的 一个边缘 到 另一个与之相对的边缘 与相机本身所成的夹角。
_（这里的定义可能不太直观，你可以去搜一下视场角的图示；_
_或者如果你玩过《我的世界》，你应该注意到那个“视场角”的设置了：你设置的视场角越大，看到的范围越宽阔——你可以暂时这样理解）_
鉴于我们的图像不是正方形的，水平视场角和竖直视场角是不一样的。我个人习惯角度制的竖直视场角，在初始化的时候再把角度转成弧度——具体怎么操作凭你自己的喜好。


相机观察的几何学原理
------------------------
首先，我们保持光线从原点发出，穿过 $z=-1$ 的平面。当然，只要我们让 $h$ 和 $z$ 成比例， $z$ 取何值都没问题。如下图：

    ![Figure [cam-view-geom]: Camera viewing geometry (from the side)
    ](../images/fig-1.18-cam-view-geom.jpg)


<div class='together'>
由上图不难看出，$h = \tan(\frac{\theta}{2})$. 对相机代码进行如下修改：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class camera {
      public:
        double aspect_ratio      = 1.0;  // Ratio of image width over height
        int    image_width       = 100;  // Rendered image width in pixel count
        int    samples_per_pixel = 10;   // Count of random samples for each pixel
        int    max_depth         = 10;   // Maximum number of ray bounces into scene


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        double vfov = 90;  // Vertical view angle (field of view)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        void render(const hittable& world) {
        ...

      private:
        ...

        void initialize() {
            image_height = int(image_width / aspect_ratio);
            image_height = (image_height < 1) ? 1 : image_height;

            pixel_samples_scale = 1.0 / samples_per_pixel;

            center = point3(0, 0, 0);

            // Determine viewport dimensions.
            auto focal_length = 1.0;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            auto theta = degrees_to_radians(vfov);
            auto h = std::tan(theta/2);
            auto viewport_height = 2 * h * focal_length;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            auto viewport_width = viewport_height * (double(image_width)/image_height);

            // Calculate the vectors across the horizontal and down the vertical viewport edges.
            auto viewport_u = vec3(viewport_width, 0, 0);
            auto viewport_v = vec3(0, -viewport_height, 0);

            // Calculate the horizontal and vertical delta vectors from pixel to pixel.
            pixel_delta_u = viewport_u / image_width;
            pixel_delta_v = viewport_v / image_height;

            // Calculate the location of the upper left pixel.
            auto viewport_upper_left =
                center - vec3(0, 0, focal_length) - viewport_u/2 - viewport_v/2;
            pixel00_loc = viewport_upper_left + 0.5 * (pixel_delta_u + pixel_delta_v);
        }

        ...
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [camera-fov]: <kbd>[camera.h]</kbd> 添加了可调节的视场角（fov）功能的相机]

</div>


<div class='together'>
渲染两个互相接触的球，视场角为 90&deg;：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    int main() {
        hittable_list world;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        auto R = std::cos(pi/4);

        auto material_left  = make_shared<lambertian>(color(0,0,1));
        auto material_right = make_shared<lambertian>(color(1,0,0));

        world.add(make_shared<sphere>(point3(-R, 0, -1), R, material_left));
        world.add(make_shared<sphere>(point3( R, 0, -1), R, material_right));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        camera cam;

        cam.aspect_ratio      = 16.0 / 9.0;
        cam.image_width       = 400;
        cam.samples_per_pixel = 100;
        cam.max_depth         = 50;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        cam.vfov = 90;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        cam.render(world);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [scene-wide-angle]: <kbd>[main.cc]</kbd> 广角镜头]

</div>

<div class='together'>
渲染得到以下结果：

  ![<span class='num'>Image 19:</span> 广角镜头：渲染结果
  ](../images/img-1.19-wide-view.png class='pixel')

</div>


更改相机的位置和朝向
---------------------
现在实现让相机可以在任何一个点以任何方向观察的功能。开始之前，先规定有关的点的名字：称相机所在的点为 **lookfrom**，
称相机正在观察的点叫做 **lookat**。（如果你愿意，之后也可以用向量来定义 lookat）

还要找一种方法定义相机的滚转角（roll），或者说相机“侧向”的倾斜：相机围绕 lookat-lookfrom 轴的旋转角度。
举例来说，你在看东西的时候，除了你人站立的位置可以改变、观察点可以改变，你还可以把头倾斜不同的角度。
可以定义一个 **up** 向量（即定义相机的上方是哪个方向）来实现这个功能。

    ![Figure [cam-view-dir]: 相机观察方向示意](../images/fig-1.19-cam-view-dir.jpg)

除了与观察方向平行的 up 向量都是可以接受的。把 up 向量投影到与视线方向向量正交（垂直）的平面上，
就可以得到一个相对于相机的上向量_（投影前，上向量不一定与视线方向垂直；但是投影后，一定垂直）_
一般习惯把这个向量命名为 **view up** 或者 **vup**。在一系列的向量叉乘和归一化后，
可以得到一组正交向量 $(u,v,w)$ 描述相机的朝向。其中 $u$ 指向相机的右方，$v$ 指向相机的上方，
$w$ 指向与相机观察方向相反的方向（因为我们用的右手坐标系）。相机目前仍然位于原点。

    ![Figure [cam-view-up]: Camera view up direction](../images/fig-1.20-cam-view-up.jpg)

和之前一样，当固定的相机朝向 $-Z$ 时，这个方向任意的相机朝向 $-w$。
另外记住，vup 的方向可以但不一定是 $(0,1,0)$. 选择这个向量只是方便让相机自行保持水平，如果你要用些疯狂的相机角度做实验的话，也可以使用别的上向量。


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class camera {
    public:
        double aspect_ratio      = 1.0;  // Ratio of image width over height
        int    image_width       = 100;  // Rendered image width in pixel count
        int    samples_per_pixel = 10;   // Count of random samples for each pixel
        int    max_depth         = 10;   // Maximum number of ray bounces into scene

        double vfov     = 90;              // Vertical view angle (field of view)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        point3 lookfrom = point3(0,0,0);   // Point camera is looking from
        point3 lookat   = point3(0,0,-1);  // Point camera is looking at
        vec3   vup      = vec3(0,1,0);     // Camera-relative "up" direction
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        ...

    private:
        int    image_height;         // Rendered image height
        double pixel_samples_scale;  // Color scale factor for a sum of pixel samples
        point3 center;               // Camera center
        point3 pixel00_loc;          // Location of pixel 0, 0
        vec3   pixel_delta_u;        // Offset to pixel to the right
        vec3   pixel_delta_v;        // Offset to pixel below
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        vec3   u, v, w;              // Camera frame basis vectors
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        void initialize() {
            image_height = int(image_width / aspect_ratio);
            image_height = (image_height < 1) ? 1 : image_height;

            pixel_samples_scale = 1.0 / samples_per_pixel;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            center = lookfrom;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

            // Determine viewport dimensions.
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            auto focal_length = (lookfrom - lookat).length();
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            auto theta = degrees_to_radians(vfov);
            auto h = std::tan(theta/2);
            auto viewport_height = 2 * h * focal_length;
            auto viewport_width = viewport_height * (double(image_width)/image_height);


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            // Calculate the u,v,w unit basis vectors for the camera coordinate frame.
            w = unit_vector(lookfrom - lookat);
            u = unit_vector(cross(vup, w));
            v = cross(w, u);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

            // Calculate the vectors across the horizontal and down the vertical viewport edges.
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            vec3 viewport_u = viewport_width * u;    // Vector across viewport horizontal edge
            vec3 viewport_v = viewport_height * -v;  // Vector down viewport vertical edge
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

            // Calculate the horizontal and vertical delta vectors from pixel to pixel.
            pixel_delta_u = viewport_u / image_width;
            pixel_delta_v = viewport_v / image_height;

            // Calculate the location of the upper left pixel.
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            auto viewport_upper_left = center - (focal_length * w) - viewport_u/2 - viewport_v/2;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            pixel00_loc = viewport_upper_left + 0.5 * (pixel_delta_u + pixel_delta_v);
        }

        ...

    private:
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [camera-orient]: <kbd>[camera.h]</kbd> 可以改变位置和朝向的相机]


<div class='together'>
恢复之前的场景，然后试试现在的相机：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    int main() {
        hittable_list world;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        auto material_ground = make_shared<lambertian>(color(0.8, 0.8, 0.0));
        auto material_center = make_shared<lambertian>(color(0.1, 0.2, 0.5));
        auto material_left   = make_shared<dielectric>(1.50);
        auto material_bubble = make_shared<dielectric>(1.00 / 1.50);
        auto material_right  = make_shared<metal>(color(0.8, 0.6, 0.2), 1.0);

        world.add(make_shared<sphere>(point3( 0.0, -100.5, -1.0), 100.0, material_ground));
        world.add(make_shared<sphere>(point3( 0.0,    0.0, -1.2),   0.5, material_center));
        world.add(make_shared<sphere>(point3(-1.0,    0.0, -1.0),   0.5, material_left));
        world.add(make_shared<sphere>(point3(-1.0,    0.0, -1.0),   0.4, material_bubble));
        world.add(make_shared<sphere>(point3( 1.0,    0.0, -1.0),   0.5, material_right));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        camera cam;

        cam.aspect_ratio      = 16.0 / 9.0;
        cam.image_width       = 400;
        cam.samples_per_pixel = 100;
        cam.max_depth         = 50;


        cam.vfov     = 90;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        cam.lookfrom = point3(-2,2,1);
        cam.lookat   = point3(0,0,-1);
        cam.vup      = vec3(0,1,0);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        cam.render(world);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [scene-free-view]: <kbd>[main.cc]</kbd> 使用一个不同的观察点]

</div>

<div class='together'>
渲染得到以下结果：

  ![<span class='num'>Image 20:</span> 远景：渲染结果
  ](../images/img-1.20-view-distant.png class='pixel')

</div>

<div class='together'>
还可以改变视场角：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        cam.vfov     = 20;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [change-field-view]: <kbd>[main.cc]</kbd> 改变视场角]

</div>

<div class='together'>
渲染得到以下结果：

  ![<span class='num'>Image 21:</span> 镜头拉近：渲染结果](../images/img-1.21-view-zoom.png class='pixel')

</div>



散焦模糊
====================================================================================================
终于到了最后一节了：**散焦模糊**（defocus blur）。摄影家们一般管这个叫 **景深**（depth of field），
所以什么“散焦模糊”的黑话仅限给其他光追爱好者说说，其他人真不一定听不懂你指的什么。

之所以现实生活中的摄像机拍出来的照片有散焦模糊现象，是因为它们有一个“大洞”_也就是镜头_来收集光线，
而不是_像我们的光追程序一样的_用针孔大的一点收集光线_（还记得到吗？我们的“光线”都是从一点发出的）_。
如果镜头只是一个纯粹的大洞，所有的东西看起来都是散焦的，正因为此镜头里面还要安装透镜，好让处于某个特定距离的物体的像可以聚焦在传感器或者胶片上。
只有处在那一距离的物体看起来是清晰的，随着距离偏差越来越大，物体看起来会越来越模糊（模糊程度与距离偏差成线性关系）。
我们可以这样理解：对于处在那一特定距离的一点，它发出的光线，经过透镜偏折后，仍然会聚集到传感器或者胶片上的一点

位于其内部的物体都可以完美聚焦的（或者说，对于某相机，可以完美聚焦的所有点构成的）平面，叫做“对焦平面”（focus plane）。
我们将相机中心到对焦平面的距离称为**对焦距离**（focus distance）。
注意区分此概念与**焦距**（focal length）的区别。后者一般指相机中心与图像平面（4.2 节中的视口平面，也就是我们用来构造光线的那个平面）的距离，这两者不一定相等。
但是，我们暂时可以把它们当作相等的：考虑把图像平面与对焦平面重合。

在现实生活中的摄像机里，对焦距离由透镜与传感器/胶片之间的距离决定。这就是为什么改变摄像机的对焦距离时，需要把透镜与相机本体的距离调远调近
（在手机里面，是透镜不动，传感器移动）。“光圈”（aperture）控制了透镜的有效大小。现实中，如果你想要更多的光线进入镜头，调大光圈，这时候散焦模糊的程度会加大。
在光追程序中，不存在光线多少的问题，所以光圈大小只用来控制散焦模糊的程度。


薄透镜估计法
--------------
现实中的摄像机有着复杂的复合透镜。类似地，我们也可以按照以下顺序模拟相机：传感器、透镜，最后是光圈。
然后就可以计算得到应该往哪发射光线，最后将得到的图像上下翻转（在胶片上，图像在投影后上下发生翻转）。
但是实操一般不会这样做：完全模拟相机内部的结构的不仅没有必要，对于仅仅渲染“相机”外的图像的需求而言，甚至还把问题复杂化了。

    ![Figure [cam-lens]: 摄像机和镜片的模式图](../images/fig-1.21-cam-lens.jpg)

相反，我们一般使用薄透镜估计法（thin lens approximation）。考虑从一个无限薄的“透镜”平面发射出光线，穿过对焦平面_（已经介绍过它的意义了）_。

实际操作中，我们可以直接把视口平面与对焦平面重叠。综上：

  1. 对焦平面应当与相机观察方向正交（垂直）；
  2. 对焦距离为相机距离与对焦平面之间的距离；
  3. 视口平面与对焦平面重叠，相机观察方向向量过视口平面中心；
  4. 像素网格在视口平面内部（位于三维空间中）；
  5. 对于某像素，采样时在其周围随机选择采样点生成光线；
  6. 光线的起点在相机“透镜”的范围随机取得。

  ![Figure [cam-film-plane]: Camera focus plane](../images/fig-1.22-cam-film-plane.jpg)


生成采样光线
--------------
如果没有散焦模糊的话，所有的光线都从相机中心，也就是 lookfrom 发出。要实现散焦模糊，我们构造一个圆心位于相机中心的假想圆盘。
这个“散焦圆盘”的半径越大，散焦模糊的效果就越明显。你也可以把没有这个功能的相机看作是一个散焦圆盘半径为零的相机，因此所有的光线都会从圆盘中心（lookfrom）发出。

散焦圆盘取多大合适呢？不确定，因此要给 `camera` 相机类添加一个有关的参数。直接设置圆盘的半径也不是不行，但这样如果对焦距离变化，模糊的程度也会变化，这样不好。
一个更好的方案是，我们指定顶点位于视口中心，底面为散焦圆盘的圆锥的顶角大小，使用顶角大小和对焦距离计算得出圆盘的半径。这样哪怕对焦距离改变，模糊的程度也能保证一致。

因为我们要从散焦圆盘中随机取点，最好为此创建一个函数 `random_in_unit_disk()`，此函数和 `random_in_unit_sphere()` 类似，但是前者比后者少一个维度。


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    ...

    inline vec3 unit_vector(const vec3& u) {
        return v / v.length();
    }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    inline vec3 random_in_unit_disk() {
        while (true) {
            auto p = vec3(random_double(-1,1), random_double(-1,1), 0);
            if (p.length_squared() < 1)
                return p;
        }
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

    ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [rand-in-unit-disk]: <kbd>[vec3.h]</kbd> 在一个单位圆盘内随机取点]

更新相机类的代码，让光线从散焦圆盘发出：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    class camera {
    public:
        double aspect_ratio      = 1.0;  // Ratio of image width over height
        int    image_width       = 100;  // Rendered image width in pixel count
        int    samples_per_pixel = 10;   // Count of random samples for each pixel
        int    max_depth         = 10;   // Maximum number of ray bounces into scene

        double vfov     = 90;              // Vertical view angle (field of view)
        point3 lookfrom = point3(0,0,0);   // Point camera is looking from
        point3 lookat   = point3(0,0,-1);  // Point camera is looking at
        vec3   vup      = vec3(0,1,0);     // Camera-relative "up" direction


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        double defocus_angle = 0;  // Variation angle of rays through each pixel
        double focus_dist = 10;    // Distance from camera lookfrom point to plane of perfect focus
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        ...

    private:
        int    image_height;         // Rendered image height
        double pixel_samples_scale;  // Color scale factor for a sum of pixel samples
        point3 center;               // Camera center
        point3 pixel00_loc;          // Location of pixel 0, 0
        vec3   pixel_delta_u;        // Offset to pixel to the right
        vec3   pixel_delta_v;        // Offset to pixel below
        vec3   u, v, w;              // Camera frame basis vectors
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        vec3   defocus_disk_u;       // Defocus disk horizontal radius
        vec3   defocus_disk_v;       // Defocus disk vertical radius
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        void initialize() {
            image_height = int(image_width / aspect_ratio);
            image_height = (image_height < 1) ? 1 : image_height;

            pixel_samples_scale = 1.0 / samples_per_pixel;

            center = lookfrom;

            // Determine viewport dimensions.
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ delete
            auto focal_length = (lookfrom - lookat).length();
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            auto theta = degrees_to_radians(vfov);
            auto h = std::tan(theta/2);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            auto viewport_height = 2 * h * focus_dist;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            auto viewport_width = viewport_height * (double(image_width)/image_height);

            // Calculate the u,v,w unit basis vectors for the camera coordinate frame.
            w = unit_vector(lookfrom - lookat);
            u = unit_vector(cross(vup, w));
            v = cross(w, u);

            // Calculate the vectors across the horizontal and down the vertical viewport edges.
            vec3 viewport_u = viewport_width * u;    // Vector across viewport horizontal edge
            vec3 viewport_v = viewport_height * -v;  // Vector down viewport vertical edge

            // Calculate the horizontal and vertical delta vectors to the next pixel.
            pixel_delta_u = viewport_u / image_width;
            pixel_delta_v = viewport_v / image_height;

            // Calculate the location of the upper left pixel.
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            auto viewport_upper_left = center - (focus_dist * w) - viewport_u/2 - viewport_v/2;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            pixel00_loc = viewport_upper_left + 0.5 * (pixel_delta_u + pixel_delta_v);


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            // Calculate the camera defocus disk basis vectors.
            auto defocus_radius = focus_dist * std::tan(degrees_to_radians(defocus_angle / 2));
            defocus_disk_u = u * defocus_radius;
            defocus_disk_v = v * defocus_radius;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
        }

        ray get_ray(int i, int j) const {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            // Construct a camera ray originating from the defocus disk and directed at a randomly
            // sampled point around the pixel location i, j.
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

            auto offset = sample_square();
            auto pixel_sample = pixel00_loc
                            + ((i + offset.x()) * pixel_delta_u)
                            + ((j + offset.y()) * pixel_delta_v);


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            auto ray_origin = (defocus_angle <= 0) ? center : defocus_disk_sample();
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            auto ray_direction = pixel_sample - ray_origin;

            return ray(ray_origin, ray_direction);
        }

        vec3 sample_square() const {
            ...
        }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        point3 defocus_disk_sample() const {
            // Returns a random point in the camera defocus disk.
            auto p = random_in_unit_disk();
            return center + (p[0] * defocus_disk_u) + (p[1] * defocus_disk_v);
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        color ray_color(const ray& r, int depth, const hittable& world) const {
            ...
        }
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [camera-dof]: <kbd>[camera.h]</kbd> 景深（散焦模糊）可调的相机]


<div class='together'>
使用一个大光圈：

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    int main() {
        ...

        camera cam;

        cam.aspect_ratio      = 16.0 / 9.0;
        cam.image_width       = 400;
        cam.samples_per_pixel = 100;
        cam.max_depth         = 50;

        cam.vfov     = 20;
        cam.lookfrom = point3(-2,2,1);
        cam.lookat   = point3(0,0,-1);
        cam.vup      = vec3(0,1,0);


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        cam.defocus_angle = 10.0;
        cam.focus_dist    = 3.4;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        cam.render(world);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [scene-camera-dof]: <kbd>[main.cc]</kbd> 设置景深]

</div>

<div class='together'>
渲染得到以下结果：

  ![<span class='num'>Image 22:</span> 球体，相机有景深：渲染结果
  ](../images/img-1.22-depth-of-field.png class='pixel')

</div>



下一步做什么？
====================================================================================================

渲染最终成果
------------
渲染这本书的封面——一大堆球吧！

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    int main() {
        hittable_list world;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        auto ground_material = make_shared<lambertian>(color(0.5, 0.5, 0.5));
        world.add(make_shared<sphere>(point3(0,-1000,0), 1000, ground_material));

        for (int a = -11; a < 11; a++) {
            for (int b = -11; b < 11; b++) {
                auto choose_mat = random_double();
                point3 center(a + 0.9*random_double(), 0.2, b + 0.9*random_double());

                if ((center - point3(4, 0.2, 0)).length() > 0.9) {
                    shared_ptr<material> sphere_material;

                    if (choose_mat < 0.8) {
                        // diffuse
                        auto albedo = color::random() * color::random();
                        sphere_material = make_shared<lambertian>(albedo);
                        world.add(make_shared<sphere>(center, 0.2, sphere_material));
                    } else if (choose_mat < 0.95) {
                        // metal
                        auto albedo = color::random(0.5, 1);
                        auto fuzz = random_double(0, 0.5);
                        sphere_material = make_shared<metal>(albedo, fuzz);
                        world.add(make_shared<sphere>(center, 0.2, sphere_material));
                    } else {
                        // glass
                        sphere_material = make_shared<dielectric>(1.5);
                        world.add(make_shared<sphere>(center, 0.2, sphere_material));
                    }
                }
            }
        }

        auto material1 = make_shared<dielectric>(1.5);
        world.add(make_shared<sphere>(point3(0, 1, 0), 1.0, material1));

        auto material2 = make_shared<lambertian>(color(0.4, 0.2, 0.1));
        world.add(make_shared<sphere>(point3(-4, 1, 0), 1.0, material2));

        auto material3 = make_shared<metal>(color(0.7, 0.6, 0.5), 0.0);
        world.add(make_shared<sphere>(point3(4, 1, 0), 1.0, material3));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        camera cam;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        cam.aspect_ratio      = 16.0 / 9.0;
        cam.image_width       = 1200;
        cam.samples_per_pixel = 500;
        cam.max_depth         = 50;

        cam.vfov     = 20;
        cam.lookfrom = point3(13,2,3);
        cam.lookat   = point3(0,0,0);
        cam.vup      = vec3(0,1,0);

        cam.defocus_angle = 0.6;
        cam.focus_dist    = 10.0;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        cam.render(world);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [scene-final]: <kbd>[main.cc]</kbd> Final scene]

请注意，上述代码使用了远高于书中其它地方样例代码的 `samples_per_pixel`，达到了 500 甚至更高，因此渲染这张图像需要好一会。
之所以我们之前把单个像素采样数设的很低，是因为要方便开发和调试。

<div class='together'>
渲染得到：

  ![<span class='num'>Image 23:</span> Final scene](../images/img-1.23-book1-final.jpg)

</div>

你可能注意到了，那些玻璃球没有阴影，导致它们看起来仿佛是悬浮在空中一般。这不是 bug，现实生活中没有太多玻璃球，因此你对它们的光学性质没有太多直观印象，
但哪怕是真的玻璃球看起来也很古怪，而且在阴天的光照下，它们看起来也像浮在空中。另外，由于玻璃球不是阻碍了光线，而只是偏转了光线，所以仍然有很多光可以照射到其下面的地面，
因此地面并不会因为上面放了玻璃球而明显变暗。


接下来……
-----------------
终于做完光追渲染器了！接下来做什么呢……

  - 第二册：《两个周末做光追》（_Ray Tracing: The Next Week_）

  - 第三册：《一辈子做光追》（_Ray Tracing: The Rest of Your Life_）

_目前只有第二册的 3.0 版本有中文翻译。4.0 版的话，目前似乎只有第一册有翻译，也就是这个版本。_
_但我暂时没有继续翻译的计划。——译者_


补充信息
---------
敬请参阅：
<https://raytracing.github.io>



译后记
====================================================================================================
国庆节的时候想给自己找点事情做，正好读了这本书，觉得写的相当不错，而且渐进式的教学方法对于我一个几乎没有图形学基础的大一新生也相当友好，就想要把它翻译为中文。
这时候知乎上已经有[本书的 3.0 版本翻译了](https://zhuanlan.zhihu.com/p/128685960)，本书翻译过程中也部分参考了该译版，在此表示感谢。

虽然主要的翻译工作已经基本告一段落，但仍然有许多不足亟待解决：代码注释部分未予翻译（这个只能之后解决了）；有些句子太长太乱、逻辑不太通顺，或者不符合中文表述习惯，不利于理解；使用了大量本人的习惯性表述等等。

本人才疏学浅，英语翻译、汉语写作、计算机图形学水平有限，翻译难免有错漏、模糊之处，还望诸位读者斧正。

作者： [Peter Shirley](https://github.com/petershirley), [Trevor David Black](https://github.com/trevordblack), [Steve Hollasch](https://github.com/hollasch)

译者： 李梓萌 西北工业大学 2024 级


<!-- Markdeep: https://casual-effects.com/markdeep/ -->
<link rel='stylesheet' href='../style/book.css'>
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script src="markdeep.min.js"></script>
<script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js"></script>
<script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
